\chapter{طراحی یک پلتفرم \lr{MLOps}}
 
\section{مقدمه}
در این بخش می خواهیم مقدمه ای از طراحی و هدف آن بنویسیم

\section{سیستم مدیریت پلتفرم}
\subsection{مدیریت پیکربندی و فراهم سازی زیرساخت}
در دنیای فناوری اطلاعات، زیرساخت‌های تغییرناپذیر\footnote{\lr{Immutable Infrastructure}} و تغییرپذیر\footnote{\lr{Mutable Infrastructure}} دو رویکرد مهم در مدیریت و نگهداری سیستم‌ها هستند. زیرساخت‌های تغییرناپذیر به سیستم‌هایی اشاره دارند که پس از ایجاد، بدون تغییر باقی می‌مانند و در صورت نیاز به تغییر، سیستم های جدید جایگزین آنها می‌شوند. این رویکرد با مزایایی همچون کاهش پیچیدگی‌های مدیریتی، افزایش قابلیت پیش‌بینی و کاهش ریسک‌های مرتبط با تغییرات ناخواسته همراه است \cite{DevopsIaac2}. به کمک ابزارهایی مانند داکر و کوبرنتیز، پیاده‌سازی زیرساخت‌های تغییرناپذیر امکان‌پذیر است و از قابلیت مقیاس‌پذیری بالایی برخوردارند. سیستم‌های ابری غالباً از روش تغییرناپذیر استفاده کرده تا از مزایای آن بهره‌مند شوند. در مقابل، زیرساخت‌های تغییرپذیر به سیستم‌هایی اشاره دارند که می‌توانند به طور پویا تغییر کنند و تنظیمات و پیکربندی‌های جدید را بپذیرند. این رویکرد، انعطاف‌پذیری بیشتری را فراهم می‌کند و برای محیط‌هایی که نیاز به تغییرات مکرر دارند، مناسب‌تر است. با این حال، مدیریت تغییرات در زیرساخت‌های تغییرپذیر ممکن است چالش‌های بیشتری از جمله افزایش ریسک خطاها و نیاز به نظارت مداوم به همراه داشته باشد. انتخاب بین این دو رویکرد به نیازها و اولویت‌های سازمان بستگی دارد. در حالی که زیرساخت‌های تغییرناپذیر برای محیط‌های تولید با نیاز به ثبات و قابلیت پیش‌بینی بالا مناسب‌ترند، زیرساخت‌های تغییرپذیر برای محیط‌های توسعه و آزمایش که نیاز به انعطاف‌پذیری دارند، کاربرد بیشتری دارند \cite{DevopsIaac1}. این دو مفهوم به صورت مستقیم با مدیریت پیکربندی وفراهم سازی زیرساخت مرتبط هستند.
\subsubsection{مدیریت پیکربندی}
مدیریت پیکربندی فرآیندی است که بر روی نگهداری و کنترل پیکربندی سیستم‌ها و نرم‌افزارها تمرکز دارد. هدف اصلی این فرآیند، اطمینان از سازگاری و پایداری محیط‌های \lr{IT} در طول زمان است. مدیریت پیکربندی شامل فعالیت‌هایی مانند نگهداری نسخه‌های مختلف نرم‌افزار، مستندسازی تغییرات و اطمینان از تطابق سیستم‌ها با استانداردهای تعیین شده می‌باشد. ابزارهای مدیریت پیکربندی مانند \lr{Ansible} و \lr{Puppet} به سازمان‌ها کمک می‌کنند تا فرآیندهای خودکارسازی پیکربندی را پیاده‌سازی کنند. این ابزارها از فایل‌های متنی (مانند \lr{Playbook}ها در \lr{Ansible}) برای تعریف وضعیت مطلوب سیستم‌ها استفاده می‌کنند. \lr{Ansible} \cite{Ansible} به دلیل سادگی و عدم نیاز به نصب عامل\footnote{\lr{Agent}} بر روی سیستم‌های مقصد، یکی از محبوب‌ترین ابزارهای مدیریت پیکربندی است. این ابزار از پروتکل \lr{SSH} برای ارتباط با ماشین‌ها استفاده می‌کند و از زبان \lr{YAML} برای نوشتن اسکریپت‌ها بهره می‌برد، که خوانایی و قابل فهم بودن آن را تضمین می‌کند. از ابزار های مدیریت پیکربندی در زیرساخت های تغییرپذیر غالبا استفاده می شود.

\begin{figure}[!t]
	\centering
	\includegraphics[scale=0.5]{Ansible-Architecture.png}
	\caption{معماری \lr{Ansible}}
	\label{fig: ansible arch}
\end{figure}

\subsubsection{فراهم سازی زیرساخت}
فراهم سازی زیرساخت فرآیندی است که به راه‌اندازی و پیکربندی اولیه زیرساخت‌های \lr{IT} اختصاص دارد. این فرآیند شامل ایجاد و مدیریت منابعی مانند سرورها، پایگاه داده‌ها، شبکه‌ها و سایر اجزای زیرساختی است. فراهم سازی زیرساخت به صورت سنتی فرآیندی دستی و زمان‌بر بود، اما با ظهور ابزارهای نوین این فرآیند به شدت خودکار و ساده شده است. ابزارهای متن بازی مانند \lr{Terraform} برای این کار استفاده می‌شوند. این ابزارها به کاربران امکان می‌دهند تا زیرساخت‌های خود را به صورت کد\footnote{\lr{Infrastructure as Code}} تعریف کنند \cite{DevopsIaac1}. این رویکرد به ایجاد و مدیریت منابع زیرساختی به صورت قابل تکرار و پایدار کمک می‌کند. \lr{Terraform}، یکی از پرکاربردترین ابزارهای فراهم سازی زیرساخت، از زبان \lr{HCL} برای تعریف زیرساخت‌ها استفاده می‌کند. یکی از ویژگی‌های برجسته \lr{Terraform} مدیریت وابستگی‌ها بین منابع است که امکان بازگردانی\footnote{\lr{Rollback}} به وضعیت‌های قبلی را نیز فراهم می‌کند \cite{Terraform}. از این ابزار ها غالبا برای زیرساخت ها تغییرناپذیر استفاده می شود.

در زیرساخت طراحی شده که از \lr{OpenStack} برای ساخت و مدیریت ماشین های مجازی استفاده می شود، استفاده از \lr{Ansible} به عنوان ابزار مدیریت پیکربندی به دلایل متعددی مناسب است. اولاً، \lr{Ansible} با استفاده از \lr{Playbook}های \lr{YAML} امکان خودکارسازی مراحل پیکربندی را فراهم می‌کند، از جمله نصب نرم‌افزارهای مورد نیاز، تنظیمات شبکه و پیکربندی سرویس‌ها. این ویژگی باعث می‌شود که پیکربندی‌ها به صورت دقیق و بدون خطا انجام شود. ثانیاً، \lr{Ansible} بدون نیاز به نصب عامل  بر روی ماشین های مجازی کار می‌کند و از پروتکل \lr{SSH} برای ارتباط استفاده می‌کند که این امر فرآیند پیکربندی را ساده‌تر و سریع‌تر می‌سازد. همچنین، تمامی مراحل پیکربندی به صورت کد تعریف می‌شوند که امکان اجرای مجدد و دقیق همان تنظیمات را بر روی ماشین‌های جدید فراهم می‌کند. به علاوه، \lr{Ansible} دارای ماژول‌های متعددی برای تعامل با \lr{OpenStack} است که می‌تواند فرآیند ایجاد و مدیریت ماشین های مجازی را بهینه‌تر کند. پس از پیکربندی اولیه \lr{VM}ها، \lr{Ansible} می‌تواند خوشه کوبرنتیز را به صورت خودکار راه‌اندازی و پیکربندی کند. این شامل نصب ابزارهای مورد نیاز، تنظیمات شبکه و پیکربندی سرویس‌های کوبرنتیز است.
\subsection{خط لوله \lr{CI/CD}}
با افزایش استفاده از سیستم‌های ابری و رویکرد تغییرناپذیر، مفهومی با عنوان \lr{GitOps} معرفی شد که از گیت برای مدیریت زیرساخت و پیکربندی بهره می‌برد. \lr{GitOps} توسط \lr{Weaveworks} در سال ۲۰۱۷ معرفی شد که رویکردی مدرن برای پیاده سازی خط لوله \lr{CD} بر روی سیستم های ابری است. در حالی که ابزارهای سنتی تحویل مداوم عمدتاً از مدل \lr{Push} استفاده می‌کنند، \lr{GitOps} مدل \lr{Pull} را معرفی می‌کند که به خصوص با کانتینرها و پیکربندی‌های اعلامی به خوبی کار می‌کند و آن را به یک روند محبوب در اکوسیستم بومی ابر تبدیل کرده است  \cite{Devopsgitops}. از معروف ترین ابزار کلیدی که فرآیندهای \lr{GitOps} را تسهیل می‌کند می توان به \lr{ArgoCD} اشاره کرد. 



\begin{figure}[t]
	\centering
	\includegraphics[scale=0.15]{gitops-pull.png}
	\caption{استقرار مبتنی بر \lr{Pull}}
	\label{fig: gitops pull}
\end{figure}

همان طور که گفته شد دو رویکرد در پیاده سازی خط لوله \lr{CD} وجود دارد. در مدل \lr{Pull} 
(شکل 
~\ref{fig: gitops pull})
مانند \lr{GitOps}، توسعه‌دهندگان حالت مطلوب را در مخزن گیت قرار می دهند. ابزاری نظیر \lr{ArgoCD} در محیط تولید به صورت خودکار این تغییرات را شناسایی کرده و اعمال می‌کنند. این مدل امنیت را افزایش می‌دهد زیرا نیازی به اعتبارنامه‌های دسترسی مستقیم برای توسعه‌دهندگان نیست. هم چنین این مدل مشکل استقرارهای مبتنی بر \lr{Push} را حل می کند، که در آن محیط تنها زمانی به روز می شود که مخزن محیط به روز شود. 
در مقابل، در مدل \lr{Push} (شکل 
~\ref{fig: gitops push})، استقرار در محیط تولید شامل خطوط لوله \lr{CI/CD} با اسکریپت‌هایی است که با هر تغییر در گیت فعال می‌شوند. این اسکریپت‌ها معمولاً ساخت، تست و در نهایت استقرار برنامه‌ها یا تنظیم پیکربندی‌های جدید در محیط تولید را با استفاده از ابزارهای خط فرمان و اعتبارنامه‌های ارائه شده انجام می‌دهند. این مدل کنترل دقیق‌تر بر فرآیند استقرار، اعمال سریع تغییرات، انعطاف‌پذیری بالا در مدیریت سناریوهای پیچیده و پشتیبانی بهتر از تغییرات جزئی را فراهم می‌کند، که در محیط‌های متنوع و پویا بسیار مفید است \cite{Devopsgitops}.
\begin{figure}[t]
	\centering
	\includegraphics[scale=0.15]{gitops-push.png}
	\caption{استقرار مبتنی بر \lr{Push}}
	\label{fig: gitops push}
\end{figure}

به منظور پیاده‌سازی یک ابزار متن‌باز برای مدیریت خط لوله های \lr{CI/CD} که برای سیستم‌های ابری نیز مناسب باشد،  رویکرد تغییرپذیر  به همراه استراتژی استقرار مبتنی بر \lr{Push} انتخاب شده است. انتخاب رویکرد تغییرپذیر به دلیل نیاز به انعطاف‌پذیری بیشتر در محیط‌هایی که تغییرات مکرر و به‌روزرسانی‌های سریع دارند، انجام شده است. زیرساخت‌های تغییرپذیر به ما امکان می‌دهند تا به سرعت به تغییرات نیازمندی‌ها، پاسخ دهیم و تنظیمات و پیکربندی‌های جدید را به راحتی اعمال کنیم. این ویژگی در محیط‌های توسعه و آزمایش بسیار حیاتی است، زیرا تغییرات مداوم و آزمایش‌های متعدد بخشی از فرآیند توسعه نرم‌افزار هستند. هم چنین روش \lr{Push} نیز به دلیل سادگی و کارایی در اعمال به‌روزرسانی‌ها انتخاب شده است. با استفاده از این روش، می‌توانیم به‌روزرسانی‌ها را مستقیماً به سرورها ارسال کنیم و اطمینان حاصل کنیم که تمام سیستم‌ها به سرعت و بدون نیاز به مداخله دستی به‌روز می‌شوند. این رویکرد همچنین به کاهش زمان مورد نیاز برای انتشار تغییرات کمک می‌کند. در این راستا، \lr{Jenkins} به عنوان ابزار پیاده‌سازی و مدیریت خط لوله \lr{CI/CD} انتخاب شده است. جنکینز به دلیل متن‌باز بودن و دارا بودن تعداد زیادی پلاگین، انعطاف‌پذیری بسیار بالایی دارد و می‌تواند با انواع سیستم‌های ابری و رویکردهای زیرساختی سازگار شود. جنکینز همچنین با \lr{Ansible} که به عنوان ابزار مدیریت پیکربندی انتخاب شد، به خوبی سازگار است. این ترکیب به ما اجازه می‌دهد تا پیکربندی‌های پیچیده را به سادگی مدیریت کنیم و اطمینان حاصل کنیم که تمام زیرساخت‌ها به صورت هماهنگ عمل می‌کنند.
\subsubsection{طراحی خط لوله}
؟?????????
\subsection{مخزن کد منبع}

مخزن کد منبع\footnote{\lr{Source Code Repository}} یک سیستم ذخیره‌سازی و مدیریت کد است که به توسعه‌دهندگان این امکان را می‌دهد تا به صورت مشترک و هماهنگ بر روی پروژه‌های نرم‌افزاری کار کنند. این مخازن ابزارهای متعددی را برای تسهیل و بهبود فرآیند توسعه نرم‌افزار فراهم می‌کنند. یکی از اصلی‌ترین ویژگی های مخزن کد منبع، کنترل نسخه است که به توسعه‌دهندگان این امکان را می‌دهد تا تغییرات کد را پیگیری کرده و به نسخه‌های قبلی بازگردند. این ابزارها با ثبت تاریخچه تغییرات و شاخه‌بندی، امکان مدیریت همزمان چندین ویژگی یا رفع اشکال را فراهم می‌کنند بدون اینکه تغییرات یکدیگر را تحت تأثیر قرار دهند.

رایج‌ترین و پرکاربردترین این مخازن، گیت است که با ابزارهای مختلفی مانند \lr{GitHub}، \lr{GitLab} و \lr{Bitbucket} یکپارچه می‌شود. از آنجایی که یکی از شرط های پیاده سازی پلتفرم، متن باز بودن ابزار های آن می باشد، \lr{GitLab} برای مدیریت مخزن کد منبع استفاده شده است. در این طراحی \lr{Jenkins} به \lr{GitLab} به عنوان مخزن کد متصل شده و هر تغییر در کد منبع باعث اجرا شدن یک خط لوله \lr{CI/CD} مشخص توسط \lr{Jenkins} می گردد.

\subsection{مخزن مؤلفه ها}
یک مخزن مؤلفه\footnote{\lr{Artifact Repository}} یک سیستم متمرکز برای ذخیره‌سازی، مدیریت و انتشار مؤلفه های نرم‌افزاری است. این مؤلفه ها شامل هر نوع فایل باینری، کتابخانه، ماژول، پکیج، پلاگین یا حتی مستنداتی می‌شود که در طول چرخه عمر توسعه نرم‌افزار تولید می‌شود. هدف اصلی این مخازن این است که به تیم‌های توسعه اجازه دهد تا به راحتی نسخه‌های مختلفی از مؤلفه ها را مدیریت و به اشتراک بگذارند، فرآیندهای ساخت و انتشار را ساده کنند و وابستگی‌ها را طور موثرتری مدیریت کنند. همچنین، از انتشار مؤلفه هایی که هنوز تست نشده‌اند یا از نظر امنیتی مشکلاتی دارند جلوگیری می‌کنند. 
یکی از ابزارهای محبوب و متن باز برای مدیریت مخازن مؤلفه ها، \lr{Nexus} است. \lr{Nexus} از فرمت‌های مختلف مؤلفه ها مانند \lr{Helm}، \lr{apt}، \lr{PyPI} و \lr{Docker} پشتیبانی می‌کند، که این امر آن را به یک ابزار چندمنظوره برای انواع پروژه‌های نرم‌افزاری تبدیل می‌کند. مخازن مؤلفه موردنیاز برای پیاده سازی پلتفرم در 4 نوع \lr{raw}، \lr{apt}، \lr{PyPI} و \lr{Docker} می باشد.

\subsubsection{مخازن \lr{APT}}
یک سیستم مدیریت بسته در سیستم‌عامل‌های مبتنی بر دبیان است که به کاربران اجازه می‌دهد تا بسته‌های نرم‌افزاری را به راحتی نصب، به‌روزرسانی و حذف کنند. از آنجایی بسته های استفاده شده در سرور ها غالبا یکسان می باشد، به منظور افزایش سرعت پیاده سازی و اعمال تغییرات و پیکربندی تمامی بسته های مورد استفاده و نصب نشده در محیط، در \lr{Nexus} ذخیره خواهند شد. این امر با استفاده از مخازنی از نوع \lr{Proxy} انجام خواهد شد. در پیاده سازی سیستم علاوه بر بسته های موجود در \lr{APT} رسمی \lr{Ubuntu}، از مخازن \lr{Containerd} و \lr{Kubernetes} نیز برای نصب و پیاده سازی کوبرنتیز نیز استفاده شده است. علاوه بر این، یک مخزن هم برای نصب \lr{Nvidia Driver} و \lr{Nvidida CUDA Toolkit} برای استفاده از واحد پردازنده گرافیکی ایجاد خواهد شد.
\subsubsection{مخزن \lr{PyPI}}
	یک مخزن عمومی برای بسته‌های نرم‌افزاری پایتون است که به توسعه‌دهندگان اجازه می‌دهد تا کتابخانه‌ها و ابزارهای خود را منتشر، به‌روزرسانی و مدیریت کنند. کاربران می‌توانند این بسته‌ها را به‌راحتی با استفاده از ابزار \lr{pip} نصب کنند. همانند \lr{APT}، به منظور ذخیره سازی تمامی بسته های استفاده شده در محیط تولید ساخته شده اند. این امر باعث افزایش سرعت در نصب مجدد بسته ها و پایداری سیستم در زمان های قطعی یا خرابی مخازن رسمی می شود.
\subsubsection{مخزن \lr{Docker}}
	یک سرویس برای \lr{Docker Images} است که به توسعه‌دهندگان اجازه می‌دهد تا تصاویر خود را ذخیره، مدیریت و به اشتراک بگذارند. با توجه به تحریم استفاده از \lr{DockerHub} در ایران وهم چنین کند بودن راه های جایگزین در گرفتن تصاویر موردنظر از مخازن رسمی این مخزن به وجود آمده که به مخزن رسمی \lr{docker.io} پراکسی شده است. علاوه بر این تصاویر لازم برای پیاده سازی و پیکربندی محیط که با خط لوله \lr{CI/CD} ساخته شده اند نیز برای استفاده مجدد در این مخازن قرار می گیرند.
\subsubsection{مخزن \lr{raw}}
	برای ذخیره‌سازی و مدیریت فایل‌ها و داده‌هایی استفاده می‌شود که فرمت خاصی ندارند. این نوع مخزن به توسعه‌دهندگان اجازه می‌دهد تا انواع مختلف فایل‌ها، مانند اسکریپت‌ها، تصاویر، و مستندات را بدون نیاز به ساختاردهی خاصی نگهداری کنند.


\section{معماری خوشه کوبرنتیز}
در طراحی یک پلتفرم \lr{MLOps} جامع و کارآمد که تمامی ابزارهای مورد نیاز را در بر می‌گیرد، هدف اصلی ایجاد یک بستر یکپارچه، مقیاس‌پذیر و انعطاف‌پذیر برای مدیریت چرخه حیات مدل‌های یادگیری ماشین است. این پلتفرم شامل مجموعه‌ای از ابزارها و تکنولوژی‌های متن‌باز است که همگی روی خوشه کوبرنتیز مستقر می‌شوند. استفاده از کوبرنتیز در پلتفرم‌های \lr{MLOps} به دلیل قابلیت‌های منحصر به فرد آن در مدیریت خودکار، مقیاس‌پذیری و کارایی منابع است. کوبرنتیز امکان استقرار مدل‌های یادگیری ماشین در کانتینرها را به صورت پویا و قابل اطمینان فراهم می‌کند، که این امر منجر به بهبود فرایندهای استقرار و به‌روزرسانی مدل‌ها می‌شود. همچنین، کوبرنتیز با ارائه قابلیت‌های مانیتورینگ و لاگینگ پیشرفته، به تشخیص و رفع سریع مشکلات کمک می‌کند و با ابزارهایی مانند \lr{Kubeflow}، مدیریت چرخه عمر مدل‌ها را تسهیل می‌کند. این ویژگی‌ها باعث می‌شوند تا سازمان‌ها بتوانند مدل‌های خود را به طور مداوم بهبود داده و به صورت موثر در محیط‌های تولیدی مستقر کنند. در ادامه با الهام از اصول، اجزا و معماری جامع بیان شده در فصل سوم، معماری اصلی پلتفرم \lr{MLOps} را که شامل تمام ابزارهایی که بر روی خوشه کوبرنتیز پیاده سازی می شوند را طراحی کرده و برای هر بخش یک ابزار مناسب معرفی می کنیم.

\subsection{مدیریت داده و مدل}
داده ها در پلتفرم \lr{MLOps} نقش مهمی دارند. دانشمندان داده به منظور پیاده سازی یک مدل یادگیری ماشین نیاز به آموزش این مدل ها با استفاده از داده های از پیش آماده دارند. این داده ها می تواند به صورت متن، تصویر یا صوت باشد. لذا وجود یک محل ذخیره سازی داده برای نگه داری داده ها در این پلتفرم اساسی است. در کوبرنتیز، چندین روش و نوع ذخیره‌سازی داده وجود دارد که یکی از مهم ترین آن ها \lr{PVC} می باشد که از \lr{PV} برای ذخیره سازی داده ها استفاده می کند.
 
\subsubsection{حجم پایدار و فراهم سازهای پویا}
در کوبرنتیز \lr{PV} به‌عنوان منابع ذخیره‌سازی مستقل از چرخه حیات پادها عمل می‌کنند، به این معنا که داده‌ها پس از حذف یا بازسازی پادها همچنان حفظ می‌شوند. \lr{PV}ها توسط مدیر خوشه به‌صورت ایستا یا پویا ایجاد می‌شوند و می‌توانند به \lr{PVC} متصل شوند. \lr{PVC} یک درخواست برای ذخیره‌سازی است که توسط کاربران ایجاد می‌شود و پس از تخصیص، به یک \lr{PV} مرتبط می‌شود. این مکانیزم باعث می‌شود که مدیریت ذخیره‌سازی در خوشه کوبرنتیز ساده‌تر و کارآمدتر شود. \lr{PV}ها می‌توانند از انواع مختلف ذخیره‌سازی مانند دیسک‌های محلی، شبکه‌های ذخیره‌سازی\footnote{\lr{Network File System}} یا راه‌حل‌های ابری استفاده کنند. به علاوه، استفاده از \lr{PV} و \lr{PVC} امکان استفاده مجدد از منابع ذخیره‌سازی را بدون نیاز به تنظیمات دستی پیچیده، برای پادهای مختلف فراهم می‌کند \cite{Kubernetes1, Kubernetes2}.

یکی از قابلیت‌های مهم کوبرنتیز، فراهم سازی پویا\footnote{\lr{Dynamic Provisioning}} است که به‌طور خودکار \lr{PV}ها را براساس نیازهای \lr{PVC}ها و کلاس‌های ذخیره‌سازی\footnote{\lr{Storage Class}} ایجاد می‌کند. این ویژگی، نیاز به ایجاد و مدیریت دستی \lr{PV} را توسط مدیران خوشه از بین می‌برد و مدیریت ذخیره‌سازی را ساده‌تر می‌کند. با تعریف کلاس‌های ذخیره‌سازی، می‌توان انواع مختلفی از ذخیره‌سازی را با ویژگی‌های مورد نظر فراهم کرد. هنگامی که یک درخواست ذخیره‌سازی \lr{PVC} با کلاس ذخیره‌سازی مشخص ایجاد می‌شود، کوبرنتیز به طور خودکار یک \lr{PV} که متناسب با درخواست است را ایجاد و به درخواست متصل می‌کند \cite{Kubernetes1}. این فرآیند خودکار، نه تنها کارایی و بهره‌وری را افزایش می‌دهد بلکه اطمینان می‌دهد که منابع ذخیره‌سازی به صورت بهینه و کارآمد تخصیص داده می‌شوند. ابزار متن بازی که در این پلتفرم برای مدیریت و ساخت \lr{PV}ها استفاده شده است، \lr{OpenEBS} می باشد. با استفاده از این ابزار ما \lr{PV}ها مورد نیاز برای ذخیره سازی داده های پایگاه داده و ذخیره سازی شیء مانند \lr{MinIO} را ایجاد می کنیم. 

\begin{figure}[t]
	\centering
	\includegraphics[scale=0.5]{pv-pvc.png}
	\caption{نحوه کار \lr{PV} و \lr{PVC} در خوشه کوبرنتیز}
	\label{fig: pv pvc}
\end{figure}

\subsubsection{ذخیره سازی داده}
برای پلتفرم‌های \lr{MLOps} که نیاز به ذخیره‌سازی حجم زیادی از داده‌ها دارند، استفاده از فضای ذخیره‌سازی ضروری است. ذخیره‌سازی شیء\footnote{\lr{Object Storage}} یک مدل ذخیره‌سازی داده‌ است که برای مدیریت و دسترسی به داده‌های بدون ساختار مانند فایل‌های متنی، تصویری و صوتی استفاده می‌شود. در این مدل، داده‌ها به عنوان اشیاء با شناسه منحصربه‌فرد به همراه فراداده‌ها ذخیره می‌شوند. مزایای اصلی ذخیره‌سازی شیء شامل مقیاس‌پذیری بالا، هزینه کمتر و انعطاف‌پذیری در مدیریت داده‌ها است. این سیستم‌ها به راحتی می‌توانند به میلیاردها شیء افزایش یابند و برای استفاده در محیط‌های ابری، پشتیبان‌گیری و آرشیو داده‌ها مناسب هستند. همچنین، مدیریت ساده‌تر فراداده‌ها امکان جستجو و دسترسی سریع‌تر به داده‌ها را فراهم می‌کند. \lr{MinIO} \cite{MinIO} یک نرم‌افزار متن‌باز است که به منظور ارائه‌ی سرویس ذخیره‌سازی داده طراحی شده است. این نرم‌افزار به دلیل عملکرد بالا و پایداری که دارد، در محیط‌های مختلف از جمله سیستم‌های ابری به‌کار گرفته می‌شود. \lr{MinIO} به‌عنوان جایگزینی برای \lr{Amazon S3} مطرح شده و سازگاری کامل با \lr{API}های \lr{S3} را داراست، که این امر مهاجرت بین این دو سیستم را تسهیل می‌کند.

معماری \lr{MinIO} به صورت توزیع‌شده طراحی شده است که این امکان را فراهم می‌کند تا داده‌ها به صورت افقی مقیاس‌پذیر باشند. این معماری به گونه‌ای است که می‌توان با اضافه کردن گره های جدید به خوشه، ظرفیت و عملکرد سیستم را به سادگی افزایش داد. در خوشه \lr{MinIO}، داده‌ها به صورت خودکار توزیع و تکرار\footnote{\lr{Replication}} می‌شوند تا از دسترس‌پذیری بالا و تحمل خطا اطمینان حاصل شود. یکی از مهم‌ترین تکنیک‌هایی که \lr{MinIO} برای ذخیره‌سازی داده‌ها به‌کار می‌گیرد، کدگذاری پاکسازی\footnote{\lr{Erasure Coding}} است. این تکنیک به \lr{MinIO} اجازه می‌دهد تا داده‌ها را به بلوک‌های کوچک‌تر تقسیم کرده و آنها را به صورت توزیع‌شده در چندین گره ذخیره کند. در صورت خرابی یک یا چند گره، \lr{MinIO} می‌تواند داده‌ها را از بلوک‌های باقی‌مانده بازیابی کند، بدون اینکه داده‌ای از دست برود. این روش نه تنها فضای ذخیره‌سازی را بهینه می‌کند بلکه تحمل خطا سیستم را نیز افزایش می‌دهد. این ویژگی‌ها \lr{MinIO} را به انتخابی مناسب برای ذخیره‌سازی داده‌های حجیم و پشتیبان‌گیری از آن تبدیل کرده‌اند. در کنار این ها یکی از ویژگی های مهم \lr{MinIO}، سادگی و کاربرپسندی آن است. نصب و راه‌اندازی این نرم‌افزار بسیار ساده بوده و با چند فرمان ساده قابل انجام است. رابط کاربری وب و خط فرمان (\lr{mc}) نیز به کاربران اجازه می‌دهند تا مدیریت و مانیتورینگ سرورها و داده‌ها را به سادگی انجام دهند.

\begin{figure}[t]
	\centering
	\includegraphics[scale=0.8]{minio-arch.png}
	\caption{معماری \lr{MinIO}}
	\label{fig: minio arch}
\end{figure}

در معماری طراحی شده برای این پلتفرم، داده ها ابتدا در \lr{MinIO} و در باکت های مجزا ذخیره می شوند. دانشمندان داده به همراه مهندسان داده با استفاده از کتابخانه های پایتون از این داده ها استفاده کرد و پیش پردازش های موردنظر را روی داده ها انجام داده و ویژگی های موردنظر را استخراج می کنند. در نهایت این ویژگی ها را می توانند در همان \lr{MinIO} و یا در پایگاه داده هایی که به همین منظور طراحی شده ذخیره نمایند.

\subsubsection{پایگاه داده}
به منظور ذخیره سازی داده های ساختار یافته\footnote{\lr{Structured}} مانند داده های جدولی و یا ویژگی های بدست آمده در خط لوله مهندسی ویژگی می توان از پایگاه های داده استفاده نمود. در این راستا، از \lr{PostgreSQL} و \lr{Redis} به‌عنوان انباره‌های داده آنلاین و آفلاین استفاده شده است.

\lr{PostgreSQL} 
به عنوان انباره داده آفلاین مورد استفاده قرار می‌گیرد. این سیستم مدیریت پایگاه داده رابطه‌ای، به دلیل پشتیبانی از تراکنش‌های \lr{ACID}، قابلیت اطمینان بالا و توانایی پشتیبانی از انواع داده‌های پیچیده، انتخاب مناسبی برای ذخیره‌سازی داده‌های آموزشی و ویژگی های بدست آمده از آن، لاگ‌ها و اطلاعات تحلیلی است. \lr{PostgreSQL} با قابلیت‌های تحلیلی قوی و مقیاس‌پذیری مناسب، امکان تجزیه و تحلیل عمیق داده‌ها و مدیریت متاداده‌های مدل‌ها را فراهم می‌کند.

در مقابل، \lr{Redis} یک انباره داده در حافظه\footnote{\lr{In-memory}} است که برای کاربردهای آنلاین در معماری \lr{MLOps} بسیار مناسب است. \lr{Redis} به دلیل سرعت بالای خواندن و نوشتن داده‌ها و پشتیبانی از ساختارهای داده متنوع، برای ذخیره‌سازی نتایج پیش‌بینی مدل‌ها، کش کردن داده‌های موقت و مدیریت صف‌ها و تراکنش‌های سریع استفاده می‌شود. این امر به بهبود کارایی و کاهش زمان پاسخ‌دهی سیستم کمک می‌کند.

ترکیب \lr{PostgreSQL} و \lr{Redis} در این معماری، یک راهکار جامع و کارآمد برای مدیریت داده‌ها فراهم می‌کند. \lr{PostgreSQL} با امکانات پیشرفته‌اش به عنوان انباره داده آفلاین، و \lr{Redis} با سرعت بالایش به عنوان انباره داده آنلاین می تواند نیاز مختلف سیستم را فراهم سازد.

\subsection{شبکه}
بسیاری از برنامه‌های مدرن با استفاده از معماری میکروسرویس توزیع‌شده ساخته می‌شوند که باعث می‌شود هر سرویس ساده و دارای مسئولیت مشخص باشد. هر میکروسرویس \lr{API}های خود را تعریف کرده و سرویس‌ها برای پاسخگویی به درخواست‌های کاربران نهایی از این \lr{API}ها برای تعامل با یکدیگر استفاده می‌کنند. در کوبرنتیز، به منظور شبکه‌سازی برای ارتباط بین پادها و سرویس‌ها، به هر پاد یک آدرس \lr{IP} منحصربه‌فرد اختصاص داده می شود، که این امکان را فراهم می‌کند تا پادها بدون نیاز به \lr{NAT} به صورت مستقیم با یکدیگر ارتباط برقرار کنند. با افزایش تعداد این میکروسرویس‌ها، مدیریت ارتباطات، امنیت، و پایش این سرویس‌ها به چالشی بزرگ تبدیل می‌شود که می توان با \lr{Service Mesh} آن را مدیریت کرد \cite{Istio1}.

 سرویس مش یک لایه زیرساختی است که مدیریت ارتباط بین سرویس‌ها در معماری میکروسرویس‌ها را بر عهده دارد. این لایه قابلیت‌هایی مانند مشاهده‌پذیری، مدیریت ترافیک و امنیت را بدون تغییر کدهای برنامه اضافه می‌کند. \lr{Istio} یک سیستم متن‌باز برای مدیریت اتصال، امنیت و مشاهده‌پذیری در معماری‌های میکروسرویس‌ها است که به عنوان سرویس مش شناخته می شود. این ابزار با افزودن یک لایه مستقل بین میکروسرویس‌ها و شبکه، توانایی‌هایی مانند مسیریابی هوشمند، ترافیک مدیریت شده، نظارت، و امنیت را بهبود می‌بخشد. این سیستم از پروکسی‌های جانبی\footnote{\lr{Sidecar proxies}} برای کنترل ارتباطات بین میکروسرویس‌ها استفاده می‌کند، که این پروکسی‌ها معمولاً از \lr{Envoy}، یک پروکسی سریع و سبک، بهره می‌برند \cite{Istio2}. از ویژگی های مهم \lr{Istio} می توان به سه مورد زیر اشاره کرد:
\begin{itemize}
	\item 
مدیریت ترافیک:
 به کاربران اجازه می‌دهد تا ترافیک بین سرویس‌ها را به صورت دقیق کنترل و مدیریت کنند. با استفاده از قابلیت‌های مسیریابی پیشرفته، کاربران می‌توانند قوانین پیچیده‌ای برای مسیریابی ترافیک تعریف کنند. این قوانین شامل تقسیم بار\footnote{\lr{Load balancing}}، مسیریابی مبتنی بر نسخه (برای پیاده‌سازی به‌روزرسانی‌های متوالی)، و مدیریت ترافیک‌های خطا\footnote{\lr{Fault injection}} می‌شوند. این ویژگی‌ها به توسعه‌دهندگان کمک می‌کنند تا با اطمینان بیشتری به‌روزرسانی‌ها و تغییرات را در سیستم‌های خود اعمال کنند \cite{Istio2}.
 	\item 
 	امنیت:
 	امکانات امنیتی جامعی برای ارتباطات سرویس به سرویس فراهم می‌کند. این امکانات شامل احراز هویت\footnote{\lr{authentication}} و مجوزدهی\footnote{\lr{authorization}} مبتنی بر سیاست‌های امنیتی است. \lr{Istio} با استفاده از \lr{MTLS} ارتباطات بین سرویس‌ها را رمزنگاری می‌کند و اطمینان حاصل می‌کند که فقط سرویس‌های معتبر می‌توانند با یکدیگر ارتباط برقرار کنند. این قابلیت‌ها به افزایش امنیت سیستم‌های میکروسرویس کمک شایانی می‌کنند.
 	\item
مشاهده‌پذیری و نظارت:
 قابلیت‌های گسترده‌ای شامل جمع‌آوری و نمایش لاگ‌ها، متریک‌ها و تریس‌ها\footnote{\lr{Trace}} برای مشاهده‌پذیری و نظارت ارتباطات بین سرویس‌ها فراهم می‌کند. با استفاده از ابزارهای یکپارچه‌سازی شده مانند \lr{Prometheus} و \lr{Grafana}  کاربران می‌توانند به صورت جامع عملکرد و سلامت سیستم‌های خود را نظارت کنند.
 	
\end{itemize} 
 
 همان طور که معماری این سیستم را در شکل 
~\ref{fig: istio arch}
 می بینید، \lr{Istio} به دو بخش اصلی سطح داده\footnote{\lr{Data plane}} و سطح کنترل \footnote{\lr{Control plane}} تقسیم می‌شود.
 
\begin{figure}[t]
	\centering
	\includegraphics[scale=0.7]{istio.png}
	\caption{معماری \lr{Istio}}
	\label{fig: istio arch}
\end{figure}
\subsubsection{سطح داده}
سطح داده مدیریت ارتباط بین سرویس‌ها را بر عهده دارد. در یک شبکه سنتی بدون سرویس مش، شبکه نمی‌تواند ترافیک را بفهمد و بنابراین نمی‌تواند تصمیمات مبتنی بر نوع ترافیک یا منبع و مقصد آن بگیرد. با استفاده از این سیستم، هر ترافیک شبکه‌ای که از سرویس‌ها خارج یا به آن‌ها وارد می‌شود توسط یک پروکسی رهگیری می‌شود. سطح داده شامل مجموعه‌ای از پروکسی‌های هوشمند به نام \lr{Envoy} است که به صورت \lr{Sidecar} به هر سرویس در مش اضافه می‌شوند. این پروکسی‌ها وظیفه میانجی‌گری و کنترل تمامی ارتباطات شبکه‌ای بین میکروسرویس‌ها را بر عهده دارند \cite{Istio2}.

\lr{Envoy}
 پراکسی، به عنوان یک پروکسی با عملکرد بالا، قابلیت‌های گسترده‌ای را برای مدیریت ترافیک میکروسرویس‌ها در سرویس مش فراهم می‌کند. این قابلیت‌ها شامل کشف سرویس پویا است که به طور خودکار سرویس‌ها را شناسایی کرده و به تغییرات در توپولوژی پاسخ می‌دهد. تقسیم بار ترافیک را بهینه‌سازی می‌کند \cite{Istio2}. این ابزار از پروتکل‌های \lr{HTTP/2} و \lr{gRPC} برای بهبود کارایی پشتیبانی می‌کند و با استفاده از قطع کننده‌های مدار \footnote{\lr{Circuit Breakers}} از بارگذاری بیش از حد سرویس‌ها جلوگیری می‌کند. این پروکسی همچنین قابلیت بررسی سلامت سرویس‌ها، تزریق خطا برای شبیه‌سازی خرابی‌ها، و جمع‌آوری تلمتری غنی را دارد. 

\subsubsection{سطح کنترل}
سطح کنترل مسئول مدیریت و پیکربندی پروکسی‌های تشکیل دهنده سطح داده است. این سطح، پیکربندی مورد نظر شما را که از طریق سیاست‌ها و قوانین تعریف می‌شود، دریافت می‌کند و با استفاده از دید خود نسبت به سرویس‌ها در داخل مش، پروکسی‌ها را به صورت پویا برنامه‌ریزی می‌کند. هنگامی که قوانین یا محیط تغییر می‌کنند، سطح کنترل پروکسی‌ها را به روزرسانی می‌کند \cite{Istio2}. این پیکربندی پویا به مدیریت ترافیک و سیاست‌ها به صورت بلادرنگ این امکان را می‌دهد تا سرویس مش به سرعت با تغییرات نیازهای برنامه یا زیرساخت‌ ها سازگار شود. 

اصلی‌ترین جزء صفحه کنترل \lr{Istiod} نام دارد که مسئول کشف سرویس، مدیریت پیکربندی و مدیریت گواهی‌ها است. این ابزار، قواعد مسیریابی را به پیکربندی‌های \lr{Envoy} تبدیل کرده و به سایدکارها ارسال می‌کند. \lr{Istiod} به عنوان مرجع صدور گواهی\footnote{\lr{Certificate Authority}} عمل کرده و ارتباطات امن \lr{MTLS} را در صفحه داده تضمین می‌کند. همچنین، با مدیریت هویت و اعتبارنامه‌ها، احراز هویت قوی و اجرای سیاست‌های امنیتی را فراهم می‌کند. 

\subsection{مدیریت کاربران و چندمستاجری}
پشتیبانی از چندین کاربر و چندمستاجری\footnote{\lr{Multi-Tenancy}} در پلتفرم ابری یکی از ویژگی‌های کلیدی است که به کاربران مختلف اجازه می‌دهد به صورت امن و مستقل بر روی همان پلتفرم کار کنند. این قابلیت با استفاده از مفاهیم ایزوله‌سازی، احراز هویت و مجوزدهی پیاده‌سازی شده است. در ادامه به جزئیات این فرآیندها می‌پردازیم.

\subsubsection{احراز هویت}
احراز هویت در پلتفرم از طریق ترکیبی از پروتکل \lr{OIDC}\footnote{\lr{OpenID Connect}}  و \lr{Istio}،  به همراه ابزار \lr{Dex} برای مدیریت هویت\footnote{\lr{Identity Provider}} و یکپارچگی با سیستم‌های احراز هویت خارجی، انجام می‌شود. پروتکل \lr{OIDC} یک لایه احراز هویت بر روی \lr{OAuth 2.0} است که امکان تأیید هویت کاربران و دریافت اطلاعات پروفایل آنها را فراهم می‌کند \cite{OIDC1}. \lr{Dex} نیز یک سرویس منبع باز است که به عنوان یک ارائه‌دهنده هویت \lr{OIDC} عمل می‌کند و می‌تواند با سیستم‌های هویتی مختلفی مانند \lr{LDAP} و \lr{Active Directory} یکپارچه شود.

\begin{figure}[t]
	\centering
	\includegraphics[scale=0.45]{OIDC-dex.png}
	\caption{روند احراز هویت}
	\label{fig: auth flow}
\end{figure}
شکل 
~\ref{fig: auth flow}
روند احراز هویت یک کاربر با استفاده از پروتکل \lr{OIDC} را نشان می دهد. کاربران ابتدا به رابط کاربری پلتفرم ابری وارد می‌شوند. در این مرحله، \lr{Dex} به عنوان ارائه‌دهنده هویت، صفحه ورود را به کاربر نشان می‌دهد. سپس \lr{Dex} اطلاعات کاربر را از سیستم‌های احراز هویت خارجی می‌گیرد و پس از تأیید هویت، یک توکن \lr{OIDC} صادر می‌کند. پس از احراز هویت موفقیت‌آمیز، توکن \lr{OIDC} به کاربر بازگردانده می‌شود و در هر درخواست \lr{HTTP} به پلتفرم ابری، به عنوان هدر \lr{Authorization} ارسال می‌شود \cite{OIDC1}. \lr{Istio} به عنوان یک پروکسی معکوس عمل کرده و تمامی درخواست‌های ورودی را بررسی می‌کند. سرویس مش با استفاده از توکن \lr{OIDC} ارسال شده توسط کاربر، هویت وی را تأیید می‌کند. پس از تأیید هویت توسط \lr{Istio}، درخواست به سرور \lr{API} پلتفرم ابری ارسال می‌شود. سرور \lr{API} نیز هدرهای مربوط به اطلاعات هویتی را بررسی و پردازش می‌کند.

\subsubsection{ایزوله‌سازی}
ایزوله‌سازی در این پلتفرم با استفاده از \lr{namespace}های کوبرنتیز انجام می‌شود. هر \lr{namespace} به یک یا چند کاربر اختصاص داده می‌شود و منابع هر کاربر مانند خط لوله ها و داده‌ها در \lr{namespace} مخصوص به خود قرار می‌گیرند. این روش تضمین می‌کند که کاربران تنها به منابع خود دسترسی دارند و نمی‌توانند به منابع سایر کاربران دسترسی پیدا کنند.

\subsubsection{مجوزدهی}
مجوزدهی در پلتفرم ابری با استفاده از \lr{RBAC}\footnote{\lr{Role-based access control}} کوبرنتیز انجام می‌شود. مجوزها به صورت نقش‌ها تعریف شده و از طریق \lr{RoleBinding} به کاربران یا گروه‌های کاربران اختصاص داده می‌شوند \cite{Kubernetes1}. این روش به مدیران سیستم اجازه می‌دهد تا دسترسی‌های دقیقی برای کاربران تعیین کنند، مثلاً کاربری تنها بتواند خط لوله ها را مشاهده کند اما نتواند آنها را اجرا کند.

\subsection{نظارت}
نظارت در پلتفرم \lr{MLOps} برای اطمینان از عملکرد بهینه و پایداری مدل‌های یادگیری ماشین از اهمیت ویژه‌ای برخوردار است. متریک‌ها در \lr{MLOps} به سه دسته اصلی متریک‌های سیستم، متریک‌های مدل و متریک‌های داده تقسیم می‌شوند.

\subsubsection{متریک‌های سیستم}
متریک‌های سیستم اطلاعاتی درباره مصرف منابع مانند \lr{CPU}، حافظه، استفاده از دیسک و ترافیک شبکه را شامل می‌شوند. این متریک‌ها به شناسایی مشکلات زیرساختی کمک می‌کنند که ممکن است بر عملکرد کلی سیستم تأثیر بگذارند. مثلاً افزایش مصرف \lr{CPU} یا حافظه می‌تواند نشان‌دهنده بار غیرعادی یا مشکلات در کد مدل باشد.

\subsubsection{متریک‌های مدل}
متریک‌های مدل برای ارزیابی عملکرد مدل‌های یادگیری ماشین استفاده می‌شوند و شامل پارامترهایی مانند مدت زمان پیش‌بینی، دقت، \lr{F1-score} و نرخ خطا هستند. مدت زمان پیش‌بینی نشان‌دهنده مدت زمان لازم برای انجام یک پیش‌بینی است و افزایش غیرعادی آن می‌تواند نشان‌دهنده مشکلات کارایی باشد. دقت مدل به ارزیابی کیفیت پیش‌بینی‌ها کمک می‌کنند و کاهش در این متریک‌ها ممکن است نشان‌دهنده نیاز به بازآموزی مدل\footnote{\lr{Model Retraining}} باشد. نرخ خطا نیز به شناسایی مشکلات احتمالی در داده‌ها یا الگوریتم‌ها کمک می‌کند.

\subsubsection{متریک‌های داده}
متریک‌های داده شامل کیفیت داده‌ها، تغییرات در توزیع داده‌ها\footnote{\lr{Data Drift}} و نرخ داده‌های مفقود می‌باشند. این متریک‌ها برای تضمین کیفیت داده‌های ورودی و جلوگیری از بروز مشکلات ناشی از داده‌های نادرست یا ناکافی ضروری هستند. مثلاً تغییرات ناگهانی در توزیع داده‌ها می‌تواند نشان‌دهنده تغییرات در رفتار کاربران یا نقص در فرآیند جمع‌آوری داده‌ها باشد. نرخ داده‌های مفقود نیز به شناسایی مشکلات در جریان داده‌ها کمک می‌کند و از تأثیرگذاری منفی بر عملکرد مدل جلوگیری می‌کند.


 یکی از ابزارهای کلیدی برای جمع آوری این متریک ها \lr{Prometheus} است که برای جمع‌آوری، ذخیره‌سازی و مدیریت متریک‌ها به کار می‌رود. \lr{Prometheus} از یک مدل داده مبتنی بر سری‌های زمانی و یک زبان پرس‌وجوی قدرتمند به نام \lr{PromQL} استفاده می‌کند. \lr{Prometheus} متریک‌ها را از طریق \lr{scraping} از \lr{endpoint}های مشخص‌شده جمع‌آوری می‌کند. این \lr{endpoint}ها می‌توانند توسط سرویس‌ها، اپلیکیشن‌ها و مدل‌های مختلف ارائه شوند که در آن‌ها متریک‌های مختلف به صورت فرمت‌های مشخص مانند \lr{JSON} قرار دارند. هر متریک می‌تواند دارای چندین برچسب باشد که به فیلتر کردن و گروه‌بندی داده‌ها کمک می‌کند. این برچسب‌ها می‌توانند شامل نام سرویس، نسخه مدل، نام مدل و دیگر اطلاعات مرتبط باشند \cite{Prometheus1}.
 
 برای جمع‌آوری متریک‌ها، \lr{Prometheus} به طور دوره‌ای به \lr{endpoint}های مشخص‌شده مراجعه کرده و داده‌ها را دریافت می‌کند. این داده‌ها سپس در یک پایگاه داده زمان-سری ذخیره می‌شوند که امکان اجرای پرس‌وجوهای پیچیده و ایجاد هشدارهای مختلف را فراهم می‌کند. با تعریف آستانه‌های مختلف، \lr{Prometheus} می‌تواند در صورت بروز شرایط بحرانی مانند افزایش غیرعادی زمان پیش‌بینی یا مصرف بیش از حد منابع، به تیم‌ها هشدار دهد \cite{Prometheus1}. از \lr{Alertmanager} نیز در کنار \lr{Prometheus} برای مدیریت هشدارها استفاده می شود. هنگامی که یک قانون هشدار در \lr{Prometheus} فعال می‌شود، هشدار به \lr{Alertmanager} ارسال می‌شود. \lr{Alertmanager} بر اساس پیکربندی‌های تعریف‌شده، هشدار را به گیرندگان مناسب ارسال می‌کند. این گیرندگان می‌توانند شامل ایمیل‌ها، سرویس‌های پیام‌رسانی (مانند \lr{Slack}) و یا حتی \lr{runbooks}‌ها برای اجرای خودکار اقدامات باشند. در نهایت، با استفاده از داشبوردهای تعاملی و قابل سفارشی‌سازی \lr{Grafana}، تیم‌ها می‌توانند متریک‌های جمع‌آوری شده توسط \lr{Prometheus} را به صورت بصری مشاهده و تحلیل کنند و با استفاده از فیلترهای مختلف، تحلیل‌های دقیقی از عملکرد مدل‌ها و سیستم‌ها ارائه دهند \cite{Grafana} (شکل ~\ref{fig: monitoring arch}).

\begin{figure}[!t]
	\centering
	\includegraphics[scale=0.25]{prometheus-arch.png}
	\caption{معماری بخش نظارت}
	\label{fig: monitoring arch}
\end{figure} 
 
\subsection{استقرار مدل}

استقرار مدل یکی از مراحل کلیدی در فرآیند استفاده از مدل‌های یادگیری ماشین است. در این مرحله، مدل‌های آموزش دیده به صورت سرویس‌های قابل دسترسی برای پیش‌بینی\footnote{\lr{Inference}} به کار گرفته می‌شوند. استقرار مدل شامل مجموعه‌ای از فعالیت‌ها و فرآیندها می‌باشد که اطمینان حاصل می‌کند مدل‌ها به طور موثر و کارآمد در محیط تولید مورد استفاده قرار می‌گیرند. 

اهمیت استقرار مدل در یادگیری ماشین به دلیل توانایی آن در انتقال مدل‌های آموزش‌دیده از محیط‌های توسعه به محیط‌های عملیاتی است که در آن‌ها می‌توانند ارزش واقعی ایجاد کنند. بدون استقرار مدل، تمامی تلاش‌ها و منابع صرف‌شده برای آموزش مدل‌ها بی‌فایده خواهند بود، زیرا مدل‌ها نمی‌توانند در دنیای واقعی مورد استفاده قرار گیرند. استقرار مدل امکان دسترسی سریع و کارآمد به پیش‌بینی‌های مدل را برای کاربران نهایی، برنامه‌ها و سیستم‌های دیگر فراهم می‌کند. این امر نه تنها به بهبود فرآیندهای تصمیم‌گیری و کارایی کسب‌وکار کمک می‌کند، بلکه از طریق نظارت مستمر و به‌روزرسانی مدل‌ها، دقت و عملکرد آن‌ها نیز حفظ می‌شود. همچنین، استقرار مدل به سازمان‌ها اجازه می‌دهد تا مدل‌ها را به صورت مقیاس‌پذیر و با اطمینان از کارایی بالا به کار گیرند، که این خود موجب بهبود تجربیات کاربری و افزایش بهره‌وری می‌شود \cite{kubeflowforML}.

استقرار مدل‌های یادگیری ماشین به دو روش اصلی زیر انجام می‌شود: 

\begin{enumerate}
	\item
	\lr{Embedded Model Serving}:
	در استقرار جاسازی‌شده، مدل‌ها مستقیماً در برنامه اصلی تعبیه می‌شوند. این روش باعث می‌شود که مدل‌ها بالاترین عملکرد را داشته باشند و زیرساخت ساده‌تری نیاز داشته باشند، زیرا همه چیز در یک واحد مجتمع شده است. اما این روش نیازمند به‌روزرسانی مجدد برنامه در هر تغییر مدل است و مقیاس‌پذیری کمتری دارد، زیرا افزایش تعداد کاربران یا درخواست‌ها می‌تواند به کاهش عملکرد منجر شود. همچنین، باید تمام استراتژی‌های استقرار به‌صورت دستی پیاده‌سازی شوند که پیچیدگی بیشتری به همراه دارد \cite{kubeflowforML}.
	\item 
	\lr{Model as a Service (MaaS)}:
	در این نوع استقرار، مدل‌ها را به‌عنوان سرویس‌های جداگانه ارائه می‌دهد که می‌توانند از هر برنامه‌ای در سازمان مورد استفاده قرار گیرند. این روش مزایای زیادی دارد از جمله ساده‌سازی ادغام مدل‌ها با سایر فناوری‌ها و فرآیندهای سازمانی، امکان استفاده مجدد از مدل‌ها در برنامه‌های مختلف، و پشتیبانی از دستگاه‌های کم‌قدرت که نمی‌توانند مدل‌های پیچیده را اجرا کنند. \lr{MaaS} همچنین امکان استفاده از تکنیک‌های پیشرفته مانند به‌روزرسانی مدل، تشخیص انحراف مدل و غیره را فراهم می‌کند \cite{kubeflowforML}. علاوه بر این، این روش اجازه می‌دهد که مدل‌ها و برنامه‌ها به‌طور مستقل مقیاس‌بندی شوند که می‌توانند بر روی سخت‌افزارهای مختلف مانند \lr{CPU} و \lr{GPU} اجرا شوند. اما معایبی از جمله کاهش عملکرد به دلیل وجود شبکه‌های اضافی و پیچیدگی‌های مدیریت هماهنگی زمانی بین سرویس مدل و برنامه اصلی به نسبت روش قبل دارد. 
\end{enumerate}

در استقرار مدل به عنوان سرویس نیز، دو رویکرد اصلی وجود دارد. مدل به عنوان کد\footnote{\lr{Model as Code}} و مدل به عنوان داده\footnote{\lr{Model as Data}}. در رویکرد اول،‌کد مدل به طور مستقیم در پیاده‌سازی سرویس استفاده می‌شود. به عبارت دیگر، کد مدل بخشی از کد اصلی سرویس است که در آن قرار دارد. این روش می‌تواند برای پروژه‌های کوچک یا محیط‌های توسعه مناسب باشد، زیرا ساده‌تر و مستقیم‌تر است. اما وقتی مدل‌ها به روزرسانی می‌شوند، نیاز به تغییر و استقرار مجدد سرویس وجود دارد که می‌تواند زمان‌بر و پیچیده باشد. در مقابل، رویکرد مدل به عنوان داده از یک پیاده‌سازی عمومی استفاده می‌کند که توسط یک مدل با فرمت استاندارد مانند \lr{PFA}، \lr{PFA}، \lr{ONNX} و یا فرمت اصلی \lr{TensorFlow} استفاده می‌شود. این روش مزایای زیادی دارد، از جمله استانداردسازی تبادل مدل‌ها بین سرویس‌های مختلف که قابلیت جابجایی بین سیستم‌ها را فراهم می‌کند \cite{kubeflowforML}. با استفاده از این رویکرد، مدل‌ها می‌توانند به صورت مستقل از سرویس‌ها به روز شوند و نیاز به استقرار مجدد سرویس‌ها نیست. بیشتر پیاده‌سازی‌های رایج در \lr{MaaS}، مانند \lr{TFServing}، \lr{ONNX Runtime}، \lr{Triton Inference Server}، و \lr{TorchServe} از رویکرد مدل به عنوان داده استفاده می‌کنند و از فرمت های استاندارد بهره می‌برند. 

\subsubsection{الزامات و انتظارات از راه‌حل‌های استقرار مدل}

استقرار مدل‌های یادگیری ماشین نیازمند درک و مدیریت جنبه‌های مختلفی است که شامل عملیات توسعه، تحلیل، آزمایش و مدیریت مدل‌ها می‌شود. این وظایف گسترده و پیچیده هستند و باید به‌صورت جامع مدیریت شوند تا مدل‌ها به‌درستی در محیط‌های عملیاتی اجرا شوند. در ادامه به بررسی مهم‌ترین الزامات و انتظارات از راه‌حل‌های استقرار مدل می‌پردازیم \cite{kubeflowforML}.

\begin{itemize}
	\item 
	انعطاف‌پذیری فریم‌ورک:
	یکی از مهم‌ترین الزامات، انعطاف‌پذیری فریم‌ورک است. راه‌حل‌های استقرار مدل باید امکان استفاده از مدل‌هایی که با فریم‌ورک‌های مختلف مانند \lr{TensorFlow}، \lr{PyTorch}، و \lr{Scikit-learn} آموزش دیده‌اند را فراهم کنند. این انعطاف‌پذیری به سازمان‌ها این امکان را می‌دهد که بدون نگرانی از تغییرات در فریم‌ورک‌های زیرین، از همان رابط کاربری استفاده کنند و مدل‌ها را به سرعت به‌روزرسانی یا تغییر دهند.
	\item 
	بهره‌گیری از بهینه‌سازهای سخت‌افزاری:
	قابلیت بهره‌گیری از بهینه‌سازهای سخت‌افزاری نظیر \lr{GPU}ها و \lr{TPU}ها یکی دیگر از الزامات مهم است. بسیاری از مدل‌های یادگیری عمیق به دلیل پیچیدگی و عمق شبکه‌های عصبی نیاز به استفاده از این بهینه‌سازها دارند. استفاده از \lr{GPU}ها و \lr{TPU}ها می‌تواند زمان پیش‌بینی را کاهش داده و کارایی مدل را بهبود بخشد.
	\item
	مقیاس‌پذیری:
	مقیاس‌پذیری یکی دیگر از الزامات اساسی است. راه‌حل‌های استقرار باید امکان مقیاس‌پذیری نمونه‌های استقرار را هم به صورت دستی و هم با استفاده از مقیاس‌دهنده‌های خودکار فراهم کنند. این مقیاس‌پذیری باید بدون توجه به سخت‌افزار زیرین انجام شود. همچنین، مقیاس‌دهی هر یک از اجزای چرخه کاری استنتاج باید به صورت جداگانه انجام شود.
	\item 
	پشتیبانی از درخواست‌های \lr{REST} یا \lr{gRPC}:
	راه‌حل‌های استقرار باید از درخواست‌های \lr{REST} یا \lr{gRPC} پشتیبانی کنند. این قابلیت‌ها امکان تعامل سریع و کارآمد با سرور مدل را فراهم می‌کنند و به انعطاف‌پذیری بیشتر در نحوه استفاده از مدل‌ها کمک می‌کنند. 
\end{itemize}

به منظور استقرار مدل های یادگیری ماشین ابزار های متن‌باز بسیاری وجود دارند که یکی از معروف ترین این ابزارها \lr{KServe} می باشد. این ابزار یک راه‌حل پیشرفته برای استقرار و مدیریت مدل‌های یادگیری ماشین در محیط‌های تولیدی است. این ابزار به عنوان یک پروژه متن‌باز توسط \lr{Seldon}، \lr{Google}، \lr{Bloomberg}، و \lr{IBM} توسعه یافته است و هدف آن پر کردن خلاهای موجود در ابزارهای مهم دیگر مانند \lr{TFServing} و \lr{Seldon Core} است. \lr{KServe} با بهره‌گیری از اصول معماری \lr{Serverless} و استفاده از زیرساخت‌های کوبرنتیر و \lr{Knative}، پیچیدگی‌های مربوط به استقرار، مقیاس‌پذیری، و مدیریت مدل‌های یادگیری ماشین را کاهش می‌دهد. علاوه براین،‌ این ابزار از مقیاس‌پذیری دینامیک بر اساس رویدادها پشتیبانی می‌کند، که به معنای تخصیص منابع تنها در صورت نیاز است. ویژگی‌هایی مانند مقیاس به صفر\footnote{\lr{Scale to Zero}} ، بهینه‌سازی استفاده از منابع و کاهش هزینه‌ها را تضمین می‌کنند. این امر همچنین به تیم‌ها اجازه می‌دهد تا تمرکز بیشتری بر توسعه و بهبود مدل‌های خود داشته باشند، بدون نگرانی درباره پیچیدگی‌های زیرساخت \cite{KServe}.
در کنار ویژگی های مهم یاد شده،‌ \lr{KServe} از فریم‌ورک‌های مختلف یادگیری ماشین مانند \lr{TensorFlow}، \lr{XGBoost}،\lr{Scikit-learn} و \lr{PyTorch} پشتیبانی می‌کند. این قابلیت به کاربران اجازه می‌دهد تا مدل‌های خود را با استفاده از ابزارهای متنوع و مورد علاقه خود استقرار دهند. 

از اجزای کلیدی در معماری \lr{KServe} می توان به دو بخش سطح سرویس و سطح داده اشاره کرد. سطح سرویس در \lr{KServe} شامل تمام پیکربندی‌ها و مدیریت‌های مربوط به سرورها و جریان‌های کاری است. این سطح با استفاده از \lr{Knative} پیاده‌سازی شده و به طور خاص بر ارائه سرویس‌های \lr{Serverless} تمرکز دارد. \lr{Knative} یک مجموعه از اجزا است که قابلیت‌های \lr{Serverless} را برای کوبرنتیز فراهم می‌کند و شامل ویژگی‌هایی مانند مقیاس‌پذیری خودکار، مدیریت ترافیک و استقرار آسان است. این امر به \lr{KServe} اجازه می‌دهد تا به طور خودکار مقیاس‌بندی کند، منابع را بر اساس نیاز تخصیص دهد و فرایندهای استقرار را ساده‌سازی کند. در مقابل،‌ سطح داده در \lr{KServe}  شامل اجزایی است که وظایف مختلفی مانند مسیریابی درخواست‌ها، بررسی سلامت سرویس‌ها، تعادل بار، و احراز هویت و مجوزدهی را بر عهده دارند. اجزای کلیدی سطح داده شامل پیش‌بینی کننده،‌ توضیح دهنده و مبدل می باشد. هسته اصلی سطح داده پیش‌بینی کننده است که مسئول اجرای مدل‌های یادگیری ماشین و ارائه پیش‌بینی‌ها می‌باشد. هر پیش‌بینی‌کننده شامل یک مدل و یک سرور مدل است که درخواست‌های ورودی را پردازش و پاسخ می‌دهد. توضیح‌دهنده یک جزء اختیاری است که توضیحات مدل را در کنار پیش‌بینی‌ها فراهم می‌کند. این توضیحات می‌توانند به کاربران کمک کنند تا درک بهتری از نتایج مدل داشته باشند و تصمیمات بهتری بگیرند. در آخر،‌ مبدل نیز مسئول مراحل پیش‌پردازش و پس‌پردازش داده‌ها است. مبدل‌ها به کاربران اجازه می‌دهند تا داده‌ها را قبل از ارسال به مدل و پس از دریافت پیش‌بینی‌ها به شکلی خاص تبدیل کنند. این کار می‌تواند شامل پاک‌سازی داده‌ها، نرمال‌سازی، و تبدیل‌های دیگر باشد \cite{KServe} (شکل ~\ref{fig: kserve dataplane}). 

\begin{figure}[!t]
	\centering
	\includegraphics[scale=0.45]{kserve-dataplane.jpg}
	\caption{معماری سطح داده در \lr{KServe}}
	\label{fig: kserve dataplane}
\end{figure} 












