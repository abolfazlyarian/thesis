\chapter{مروری بر مفاهیم \lr{MLOps}}\label{ch:HVS}
 
\section{مقدمه}
 
در حالی که مدل‌های یادگیری ماشین به‌طور گسترده‌ای توسعه یافته‌اند، انتقال آن‌ها از مفهوم آزمایشی به محیط تولید اغلب با شکست مواجه می‌شود. این فاصله بیشتر به‌خاطر این است که تاکنون توجه اصلی روی ساخت مدل‌ها بوده است، نه روی تولید محصولات یادگیری ماشین که قابلیت استفاده در محیط تولید را دارند. علاوه بر آن، مدیریت بخش‌ها و زیرساخت‌های پیچیده‌ای که برای یک استقرار مؤثر ضروری هستند نیز در این امر مغفول مانده‌اند. برای رفع این مسئله، مفهوم عملیات یادگیری ماشین یا \lr{MLOps} معرفی شده است. \lr{MLOps} بر روی خودکارسازی و عملیاتی کردن فرآیندهای یادگیری ماشین تمرکز دارد تا انتقال پروژه‌های یادگیری ماشین از مفهوم به تولید را تسهیل کند. این رویکرد شامل دیدگاه جامعی از طراحی سیستم، هماهنگی اجزا، تعریف نقش‌ها و مسئولیت‌ها می‌باشد. هدف کاهش خطا به‌منظور افزایش قابلیت اطمینان و کارایی سیستم‌های یادگیری ماشین در کاربردهای واقعی می‌باشد. این فصل به بررسی تعریف، اصول، ابزار و معماری جامعی از یک پلتفرم \lr{MLOps} پرداخته و در نهایت، محصولات و رقبا این حوزه را بررسی می‌کند.


\section{تعریف مفاهیم اولیه}
 
 \lr{MLOps}
 یا پیاده‌سازی یادگیری ماشین به مجموعه‌ای از فرآیندها، ابزارها و شیوه‌ها جهت مدیریت چرخه توسعه مدل‌های یادگیری ماشین در یک محیط عملیاتی اشاره دارد. همچنین این چرخه شامل همکاری بین دانشمندان داده و مهندسان \lr{DevOps} است به‌گونه‌ای که این اطمینان حاصل شود که مدل‌ها به‌طور مؤثر توسعه، استقرار، پایش و به‌روزرسانی می‌شوند. هدف \lr{MLOps} افزایش سرعت، قابلیت‌اعتماد و مقیاس‌پذیری مدل‌های یادگیری ماشین و فرآیند توسعه این مدل‌ها در تولید است؛ درحالی‌که خطرات ناشی از ریسک عدم موفقیت را نیز کاهش می‌دهد. همچنین به‌کارگیری \lr{MLOps} فرآیند مدیریت را ساده‌تر کرده، کیفیت را افزایش می‌دهد و استقرار مدل‌های یادگیری عمیق و یادگیری ماشین در محیط‌های تولید با مقیاس بزرگ را خودکار می‌کند. لذا می‌توان گفت یکی از اهداف \lr{MLOps}، بهبود خودکارسازی و ارتقای کیفیت مدل‌های تولید و درعین‌حال توجه به الزامات تجاری و نظارتی است.
 
 استقرار مدل‌های یادگیری ماشین روی محیط عملیاتی در \lr{MLOps} اهمیت زیادی دارد، زیرا به سازمان‌ها کمک می‌کند تا مطمئن شوند که مدل‌هایشان در طول زمان دقیق، قابل‌اعتماد و کارآمد هستند. به‌طورکلی، \lr{MLOps} با خودکار کردن بسیاری از مراحل مربوط به استقرار و مدیریت مدل‌های یادگیری ماشین، به دانشمندان و مهندسان داده اجازه می‌دهد تا با همکاری یکدیگر به ارائه سریع‌تر و کارآمدتر مدل‌های یادگیری ماشین دست یابند.
 
\subsection{اصول}

برای تسهیل در رسیدن به اهداف فوق، تیم‌های \lr{MLOps} از اصول زیر استفاده می‌کنند:
\begin{enumerate}
	\item 
	خط لوله خودکار \lr{CI/CD} و هماهنگ‌سازی جریان کار\footnote{\lr{Workflow}}:
	خودکارسازی \lr{CI/CD} شامل مراحل ساخت، آزمایش، تحویل و استقرار است که به توسعه‌دهندگان نسبت به موفقیت یا شکست مراحل مختلف بازخورد سریعی را ارائه داده و بهره‌وری کلی را افزایش می‌دهد \cite{MLOpsPipeline1}. در همین حال، هماهنگ‌سازی جریان کاری وظایف یک خط لوله یادگیری ماشین را با استفاده از گراف‌های بدون‌حلقه‌ی جهت‌دار\footnote{\lr{Directed Acyclic Graph (DAG)}} هماهنگ می‌کند، که ترتیب اجرای وظایف را با توجه به روابط و وابستگی‌ها تعیین می‌کند. ترکیب این دو رویکرد می‌تواند به بهبود عملکرد و کارایی تیم‌های توسعه و داده‌کاوی کمک کند \cite{MLOpsWO1, MLOpsWO2}.
	\item 
	کنترل نسخه مدل‌های یادگیری ماشین، مجموعه‌داده‌ها و کد منبع:
	با استفاده از نسخه‌بندی مدل، داده و کد منبع، می‌توان هر تغییر و اصلاحی را در طول زمان دنبال کرد، که این امر به توسعه‌دهندگان و محققان اجازه می‌دهد تا به‌راحتی به نسخه‌های قبلی بازگردند و نتایج را بازبینی کنند. این قابلیت برای حفظ یکپارچگی و شفافیت در پروژه‌های نرم‌افزاری و علمی بسیار حیاتی است \cite{MLOpsPipeline1}.
	\item 
	نظارت و آموزش مداوم مدل یادگیری ماشین:
	آموزش مداوم\footnote{\lr{Continuous Training (CT)}} در یادگیری ماشین به معنای آموزش دوره‌ای مدل‌های یادگیری ماشین بر اساس داده‌های جدید است. این فرآیند همیشه شامل یک مرحله ارزیابی برای سنجش تغییرات کیفیت مدل است \cite{MLOpsCT1}. نظارت مداوم به معنای ارزیابی دوره‌ای داده‌ها، مدل‌ها (مانند دقت پیش‌بینی)، کد منبع و منابع زیرساختی است تا خطاها یا تغییرات احتمالی که بر کیفیت محصول تأثیر می‌گذارند، شناسایی شوند. این فرآیند به توسعه‌دهندگان امکان می‌دهد تا به‌سرعت مشکلات را شناسایی و برطرف کنند و از افت عملکرد مدل جلوگیری کنند. یکی از دلایل لزوم آموزش مداوم، رانش داده یا مدل\footnote{\lr{Data or Model Drift}} است، که به تغییرات تدریجی در داده‌ها یا عملکرد مدل در طول زمان اشاره دارد و می‌تواند باعث کاهش دقت پیش‌بینی‌ها شود \cite{MLOpsProd1}. این اصل در \lr{MLOps} برای اطمینان از عملکرد بهینه مدل‌ها و واکنش سریع به تغییرات محیطی و داده‌ها ضروری است. این فرآیند بهره‌وری را افزایش می‌دهد و کیفیت کلی سیستم‌های یادگیری ماشین را بهبود می‌بخشد. در نهایت، ترکیب آموزش و نظارت مداوم به توسعه‌دهندگان کمک می‌کند تا مدل‌ها را به‌روز نگه داشته و از تأثیرات منفی رانش داده یا مدل جلوگیری کنند \cite{MLOpsCT2}.
	\item 
	ثبت فراداده\footnote{\lr{Metadata}} یادگیری ماشین:
	ثبت فراداده برای هر مرحله در جریان‌کار یادگیری ماشین شامل ثبت جزئیات هر دوره آموزش مدل، مانند تاریخ و زمان آموزش، مدت‌زمان، پارامترهای استفاده شده و معیارهای عملکرد مدل می‌باشد \cite{MLOpsWO2}. علاوه بر این، جزئیات مدل که شامل داده‌ها و کدهای استفاده شده است، باید ثبت شود تا قابلیت پیگیری کامل آزمایشات فراهم گردد. این امر به توسعه‌دهندگان کمک می‌کند تا تغییرات و نتایج را به‌دقت مستند کرده و در صورت نیاز به نسخه‌های قبلی بازگردند \cite{MLOpsProd2}.
	\item 
	حلقه‌های بازخورد\footnote{\lr{feedback loops}}:
	حلقه‌های بازخورد به توسعه‌دهندگان اجازه می‌دهند تا به‌طور مداوم مدل‌ها را بهبود بخشند، مشکلات را شناسایی و رفع کنند و از افت کیفیت جلوگیری کنند. این رویکرد به تضمین کیفیت و کارایی مدل‌های یادگیری ماشین کمک می‌کند و فرآیند توسعه را به یک چرخه تکراری و قابل بهبود تبدیل می‌کند که به‌سرعت به تغییرات و نیازهای جدید پاسخ می‌دهد \cite{MLOpsProd2}. به‌عنوان مثال، یک حلقه بازخورد از مرحله مهندسی مدل آزمایشی به مرحله قبلی مهندسی ویژگی می‌تواند بسیار مفید باشد.
\end{enumerate}

می‌توان اضافه کرد که یکی از اصول مهم که کمتر جنبه فنی دارد و در روح فرهنگی \lr{DevOps} نیز جایگاه ویژه‌ای دارد، اصل همکاری\footnote{\lr{Collaboration}} است. این اصل بر امکان همکاری مشترک افراد بر روی داده‌ها، مدل‌ها و کدها تأکید دارد. علاوه بر جنبه‌های فنی، اصل همکاری به ایجاد فرهنگ کاری مشارکتی توجه دارد که هدف آن کاهش ایزوله‌سازی‌های حوزه‌ای بین نقش‌های مختلف است. چنین رویکردی باعث می‌شود تا افراد با تخصص‌های گوناگون به‌طور هم‌افزا با یکدیگر کار کنند، دانش خود را به اشتراک بگذارند و از هم بیاموزند.


\subsection{اجزاء}

پس از شناسایی اصولی که در قسمت قبل صحبت کردیم، اکنون اجزای دقیق یک معماری \lr{MLOps} را توضیح داده و ارتباط هرکدام با اصول گفته‌شده را بیان می‌کنیم.

\subsubsection{هماهنگ‌سازی جریان‌کاری}
هماهنگ‌سازی جریان‌کاری\footnote{\lr{Workflow Orchestration}} به‌عنوان یکی از اجزای حیاتی در مدیریت و خودکارسازی جریان‌های کاری پیچیده در حوزه‌های مختلف از جمله یادگیری ماشین و مهندسی داده، نقش مهمی ایفا می‌کند. این سیستم‌ها مانند شکل 
~\ref{fig: airflow pipelines}
از گراف‌های بدون حلقه جهت‌دار برای نمایش ترتیب اجرای وظایف استفاده می‌کنند. هر مرحله از این جریان‌کاری ممکن است شامل استخراج داده، آموزش مدل یا استنتاج باشد. این سیستم‌ها نه‌تنها ترتیب اجرای وظایف را مدیریت می‌کنند، بلکه وابستگی‌های متقابل بین وظایف را نیز مورد توجه قرار می‌دهند. همچنین این ابزارها به کاربران امکان می‌دهند تا جریان‌های کاری را به‌صورت خودکار و مقیاس‌پذیر اجرا کنند. این امر به‌ویژه در محیط‌های بزرگ با داده‌های کلان اهمیت دارد \cite{MLOpsWO2}.

ابزارهای متن‌باز معروف در زمینه یادگیری ماشین \lr{Apache Airflow}\cite{Airflow} و \lr{Kubeflow pipeline} می‌باشند. از \lr{Apache Airlfow} بیشتر برای استخراج، تبدیل و بارگذاری\footnote{\lr{Extract, Transform, Load (ETL)}} داده‌های بزرگ استفاده می‌کنند. \lr{Kubeflow Pipelines} نیز بخشی از پلتفرم \lr{Kubeflow}\cite{Kubeflow} است که برای اجرای جریان‌های کاری یادگیری ماشین بر روی کوبرنتیز طراحی شده است \cite{MLOpsWFCOMP1}. از این ابزار به‌طور خاص برای توسعه و استقرار مدل‌های یادگیری ماشین در محیط‌های ابری مناسب است که در فصل‌های بعدی با آن بیشتر آشنا خواهیم شد.	

\begin{figure}[t]
	\centering
	\includegraphics[scale=0.6]{Aairflow-pipeline.jpg}
	\caption{خط لوله در \lr{Apache Airlfow}}
	\label{fig: airflow pipelines}
\end{figure}

\subsubsection{انبار ویژگی}
انبار ویژگی\footnote{\lr{Feature Store}} یک سیستم مدیریت داده است که به منظور ذخیره‌سازی، مدیریت و اشتراک‌گذاری ویژگی‌های مورد استفاده در مدل‌های یادگیری ماشین طراحی شده است. این سیستم (شکل 
~\ref{fig: feature store})
دارای دو بخش اصلی است: پایگاه داده آنلاین و پایگاه داده آفلاین. هر یک از این پایگاه‌های داده نقش خاصی در فرآیند مدیریت و استفاده از ویژگی‌ها ایفا می‌کنند.

\textbf{پایگاه داده آفلاین}
برای ذخیره‌سازی و مدیریت ویژگی‌هایی استفاده می‌شود که در فرآیندهای آزمایش و تحلیل به کار می‌روند. این پایگاه داده معمولاً با تأخیر نسبتاً بیشتری نسبت به پایگاه داده آنلاین استفاده می‌شود و برای مواردی مناسب است که نیاز به پردازش حجم زیادی از داده‌ها در مدت زمان طولانی‌تر دارند. ویژگی‌هایی که در این پایگاه داده ذخیره می‌شوند، اغلب در فرآیندهای آموزش مدل‌های یادگیری ماشین مورد استفاده قرار می‌گیرند.

\textbf{پایگاه داده آنلاین}
برای ارائه ویژگی‌ها به‌صورت بلادرنگ استفاده می‌شود و تأخیر کمی دارد. این پایگاه داده‌ها برای سیستم‌هایی مناسب هستند که نیاز به پاسخگویی سریع دارند. زمانی که یک مدل یادگیری ماشین نیاز به استفاده از ویژگی‌ها برای انجام پیش‌بینی‌های فوری دارد، داده‌ها از این پایگاه داده آنلاین بازیابی می‌شوند. این نوع پایگاه داده‌ها باید توانایی پشتیبانی از حجم بالای درخواست‌ها را داشته باشند تا بتوانند عملکرد مطلوبی را در شرایط عملیاتی فراهم کنند. ویژگی‌هایی که در این پایگاه داده ذخیره می‌شوند، اغلب در فرآیندهای استنتاج مدل‌های یادگیری ماشین مورد استفاده قرار می‌گیرند.

با استفاده از انباره ویژگی توسعه‌دهندگان می‌توانند ویژگی‌های از پیش پردازش شده را به‌صورت متمرکز ذخیره کرده و به‌راحتی در پروژه‌های مختلف به اشتراک بگذارند، که این امر به تسریع فرآیند توسعه مدل‌ها و بهبود دقت پیش‌بینی‌ها کمک می‌کند. این سیستم‌ها معمولاً بر روی زیرساخت‌های ابری اجرا می‌شوند تا مقیاس‌پذیری بالا و کارایی مورد نیاز برای پردازش داده‌های کلان را فراهم کنند \cite{MLOpsCT2}. از ابزار معروف متن‌باز می‌توان به \lr{Feast}\cite{Feast} اشاره نمود.

\begin{figure}[t]
	\centering
	\includegraphics[scale=0.3]{feature-store2.jpg}
	\caption{انباره ویژگی}
	\label{fig: feature store}
\end{figure}


\subsubsection{بانک مدل}
بانک مدل\footnote{\lr{Model Registry}} یکی از ابزارهای بسیار مهم در مدیریت مدل‌های یادگیری ماشین است که به تیم‌ها کمک می‌کند تا مدل‌های خود را به‌صورت سازماندهی شده ذخیره، مدیریت و ردیابی کنند. همچنین اطلاعات مربوط به هر مدل را از جمله نسخه، تاریخ آخرین آموزش، معیارهای ارزیابی و مستندات مربوطه را نگهداری می‌کند. این امر به تیم‌ها کمک می‌کند تا با استفاده از نسخه‌های مختلف مدل‌ها، آزمایش‌های مختلفی انجام دهند و بهترین مدل را انتخاب کنند. همچنین به هنگام بروز مشکل در مدل‌های جدید، می‌توان از مدل‌های قابل‌قبول قبلی برای محیط عملیاتی استفاده کرد \cite{MLOpsCloud1}. از ابزارهای معروف متن‌باز می‌توان به \lr{MLflow}\cite{MLflow} اشاره کرد.


\subsubsection{انبار فراداده}
انبار فراداده یادگیری ماشین\footnote{\lr{ML Metadata Store}} برای پیگیری و ذخیره‌سازی اطلاعات مربوط به هر مرحله از جریان کاری یادگیری ماشین استفاده می‌شود. فراداده‌ها می‌توانند شامل جزئیاتی نظیر تاریخ و زمان آموزش مدل، مدت‌زمان هر مرحله از آموزش، پارامترهای استفاده‌شده، معیارهای عملکرد مدل، و سلسله‌مراتب مدل (مثل داده‌ها و کدهای استفاده‌شده) باشند. یکی از کاربردهای اصلی انبار فراداده‌ها، مدیریت کارآمد پروژه‌های پیچیده یادگیری ماشین است \cite{MLOpsProd2}. به‌عنوان مثال، در پروژه‌های بزرگ که شامل آزمایش‌ها و مدل‌های متعددی هستند، پیگیری دقیق و منظم فراداده‌ها می‌تواند به تیم‌ها کمک کند تا نتایج قبلی را به‌راحتی بازبینی کنند، مشکلات را شناسایی کنند و بهینه‌سازی‌های لازم را انجام دهند. \lr{MLflow} یک ابزار معروف برای یک سیستم پیشرفته مدیریت فراداده است که همراه با بانک مدل امکان مدیریت یکپارچه مدل‌ها و فراداده‌ها را فراهم می‌کند.

\subsubsection{استقرار مدل}
استقرار مدل\footnote{\lr{Model Serving}} به فرآیندی اشاره دارد که در آن مدل‌های یادگیری ماشین آماده برای استفاده، به کار گرفته می‌شوند تا به‌صورت عملیاتی به پیش‌بینی‌ها و استنتاج‌ها بپردازند. این فرآیند برای تبدیل مدل‌های آموزشی به ابزارهای قابل استفاده در محیط‌های تولیدی ضروری است و می‌تواند به‌صورت آنلاین برای پیش‌بینی‌های بلادرنگ یا به‌صورت دسته‌ای\footnote{\lr{Batch}} برای پردازش حجم بالای داده‌ها پیاده‌سازی شود. در محیط‌های عملیاتی، فرآیند استقرار مدل به سه شکل اصلی بلادرنگ، دسته‌ای و بدون سرور پیاده‌سازی می‌شود \cite{MLOpsCloud1}.

در استنتاج بلادرنگ\footnote{\lr{Real-time Inference}}، مدل‌های یادگیری ماشین به‌گونه‌ای پیاده‌سازی می‌شوند که بتوانند به‌سرعت و با کمترین تأخیر ممکن پیش‌بینی‌ها را انجام دهند. این نوع استنتاج برای کاربردهایی نظیر سیستم‌های توصیه‌گر، تحلیل داده‌های حسگرها و برنامه‌های کاربردی که نیاز به پاسخ‌های سریع دارند، مناسب است. به‌عنوان مثال، در سیستم‌های پیشنهاددهی محتوا مانند نتفلیکس یا آمازون، مدل‌ها باید به‌صورت بلادرنگ تحلیل کنند و پیشنهادهای شخصی‌سازی‌شده را ارائه دهند. تکنولوژی‌هایی مانند \lr{RESTful APIs} و \lr{gRPC} معمولاً برای پیاده‌سازی این نوع سرویس‌دهی استفاده می‌شوند.

استنتاج دسته‌ای\footnote{\lr{Batch Inference}} برای پردازش حجم وسیعی از داده‌ها به‌کار می‌رود که معمولاً به‌صورت زمان‌بندی‌شده انجام می‌شود. این روش برای تحلیل داده‌های کلان و پردازش‌های بزرگ مناسب است. به‌عنوان مثال، در تجزیه و تحلیل رفتار مشتریان یک فروشگاه آنلاین، داده‌های خریدهای گذشته می‌تواند به‌صورت دسته‌ای پردازش شود تا الگوهای مختلف شناسایی شود. ابزارهایی مانند \lr{Apache Spark}\cite{Spark} و \lr{Hadoop MapReduce}\cite{Hadoop} معمولاً برای پیاده‌سازی استنتاج دسته‌ای استفاده می‌شوند.

در استنتاج بدون سرور\footnote{\lr{Serverless Inference}}، مدل‌ها به‌صورت پویا و بر اساس تقاضا اجرا می‌شوند که هزینه و مقیاس‌پذیری را بهینه می‌کند. این نوع استنتاج زمانی مورد استفاده قرار می‌گیرد که نیاز به سرویس‌دهی مقیاس‌پذیر و مقرون‌به‌صرفه باشد. در استنتاج بدون سرور، مدل‌ها فقط زمانی که لازم است اجرا می‌شوند و بنابراین منابع بهینه‌سازی می‌شوند. سرویس‌های ابری مانند \lr{AWS Lambda} و \lr{Google Cloud Functions} معمولاً برای پیاده‌سازی این نوع استنتاج استفاده می‌شوند. از ابزارهای معروف متن‌باز برای استقرار مدل می‌توان به \lr{Knative}\cite{Knative} اشاره کرد.


\subsubsection{نظارت}
نظارت\footnote{\lr{Monitoring}} در یادگیری ماشین یکی از مؤلفه‌های حیاتی برای تضمین عملکرد بهینه مدل‌ها و زیرساخت‌های مرتبط است. نظارت مداوم بر مدل‌های یادگیری ماشین به دلایلی از جمله اطمینان از دقت پیش‌بینی‌ها، شناسایی ناهنجاری‌ها و بهبود مداوم عملکرد مدل‌ها ضروری است \cite{MLOpsData}. ابزارهایی مانند \lr{TensorBoard} و \lr{MLflow} نیز نقش مهمی در نظارت بر مدل‌های یادگیری ماشین ایفا می‌کنند. \lr{TensorBoard} به‌ویژه برای مصورسازی و تحلیل مراحل مختلف آموزش مدل‌ها مفید است. 

نظارت در یادگیری ماشین تنها به مدل‌ها محدود نمی‌شود؛ بلکه زیرساخت‌های مرتبط با یادگیری ماشین نیز نیاز به نظارت دارند. این نظارت شامل نظارت بر فرآیندهای \lr{CI/CD}، هماهنگی سرویس‌ها، خوشه‌های عملیاتی کوبرنتیز و گره‌های محاسباتی می‌شود \cite{MLOpsProd2}. یکی از ابزارهای رایج برای نظارت، \lr{Prometheus} است که به همراه \lr{Grafana} برای مصورسازی داده‌ها استفاده می‌شود. علاوه بر این، پشته \lr{ELK} (\lr{Elasticsearch}, \lr{Logstash}, \lr{Kibana}) نیز یک مجموعه قدرتمند برای جستجو، تحلیل و مصورسازی لاگ‌های سیستم است که می‌تواند به شناسایی و رفع سریع مشکلات کمک کند. ابزارهای نظارتی به مهندسان اجازه می‌دهند تا هرگونه ناهنجاری در زیرساخت‌ها را به‌سرعت شناسایی و رفع کنند، که این امر موجب کاهش زمان از کار افتادگی سیستم و افزایش بهره‌وری می‌شود.

 
\subsubsection{زیرساخت آموزش و استقرار مدل}
این زیرساخت شامل منابع محاسباتی اصلی مانند واحد پردازش مرکزی، حافظه و واحد پردازش گرافیکی\footnote{\lr{GPU}} است که برای پردازش داده‌ها و اجرای الگوریتم‌های پیچیده می‌باشد. زیرساخت‌ها می‌توانند به دو شکل توزیع‌شده\footnote{\lr{Distributed}} و غیرتوزیع‌شده پیاده‌سازی شوند. زیرساخت‌های غیرتوزیع‌شده معمولاً شامل ماشین‌های محلی هستند که با وجود سادگی در پیاده‌سازی، محدودیت‌هایی در مقیاس‌پذیری دارند. از سوی دیگر، زیرساخت‌های توزیع‌شده که معمولاً در بستر محاسبات ابری اجرا می‌شوند، امکان توزیع بار کاری بین چندین گره محاسباتی را فراهم می‌کنند و از این طریق مقیاس‌پذیری و کارایی بالاتری ارائه می‌دهند. یکی از ابزارهای محبوب برای مدیریت و هماهنگ‌سازی محاسبات توزیع‌شده، کوبرنتیز است که امکان مدیریت کانتینرها و توزیع بار کاری بین گره‌ها را فراهم می‌کند. همچنین، \lr{Red Hat OpenShift} نیز به‌عنوان یک پلتفرم دیگر شناخته می‌شود که قابلیت‌های مشابهی ارائه می‌دهد \cite{MLOpsCloud1}.

برای بهینه‌سازی عملکرد مدل‌های یادگیری عمیق، استفاده از واحد پردازش گرافیکی که برای ضرب ماتریسی بهینه‌سازی شده‌اند، استفاده می‌شود. در دستگاه‌های لبه\footnote{\lr{Edge Devices}} به دلیل محدودیت‌های فضا، توان محاسباتی و مصرف انرژی، اجرای مدل‌های یادگیری عمیق پیچیده با چالش‌های خاصی مواجه است. برای غلبه بر این محدودیت‌ها و بهینه‌سازی عملکرد مدل‌ها در این دستگاه‌ها، تکنیک‌های مختلفی مورد استفاده قرار می‌گیرد. یکی از این تکنیک‌ها، استفاده از شبکه‌های عصبی کوانتیزه شده است. در کوانتیزاسیون، وزن‌ها و محاسبات شبکه عصبی از دقت کامل (به‌عنوان مثال، اعداد با دقت 32 بیت) به اعداد با دقت پایین‌تر (مانند 8 بیت یا حتی کمتر) کاهش می‌یابند. این کاهش دقت باعث کاهش حجم مدل و کاهش نیاز به منابع محاسباتی می‌شود. علاوه بر این، با استفاده از عملیات نقطه شناور کم‌دقت، می‌توان محاسبات را سریع‌تر و با مصرف انرژی کمتری انجام داد. تکنیک دیگر، هرس کردن\footnote{\lr{Pruning}} است که شامل حذف اتصالات غیرضروری و وزن‌های کوچک در شبکه عصبی می‌شود. این فرآیند باعث کاهش تعداد پارامترهای مدل می‌شود، بدون آنکه تأثیر قابل‌توجهی بر دقت مدل بگذارد. هرس کردن مدل را سبک‌تر و اجرای آن را سریع‌تر می‌کند، که این امر برای دستگاه‌های لبه با منابع محدود بسیار مفید است.



\subsubsection{مخزن کد منبع}
مخزن کد منبع به‌عنوان یک نقطه مشترک برای نگهداری و مدیریت کدهای مربوط به مدل‌های یادگیری ماشین یک سازمان عمل می‌کند. با استفاده از سیستم‌های مدیریت نسخه مانند گیت، تیم‌ها می‌توانند به‌راحتی تغییرات کد را پیگیری کرده و در صورت لزوم به نسخه‌های قبلی کد بازگردند. این مخزن همچنین به خودکارسازی فرآیند \lr{CI/CD} کمک می‌کند، به‌طوری‌که هرگونه تغییر در کد به‌طور خودکار خط لوله را فعال کرده و تغییرات تست، ارزیابی و در محیط‌های مختلف مستقر می‌شوند. از ابزارهای متن‌باز برای پیاده‌سازی آن می‌توان به \lr{GitLab}\cite{GitLab} و \lr{Gerrit}\cite{Gerrit} اشاره نمود.

\subsubsection{خط لوله \lr{CI/CD}}
همان‌طور که در گذشته نیز راجع به آن صحبت کردیم، خط لوله \lr{CI/CD} به تیم‌ها اجازه می‌دهد تا کدهای مدل و داده‌ها را به‌صورت مداوم تست، تأیید و استقرار دهند. در این فرآیند، مدل‌ها به‌طور خودکار بازآموزی و بهبود می‌یابند و در محیط‌های مختلف (توسعه، تست، تولید) به‌صورت پیوسته به‌روزرسانی می‌شوند. این کار نه‌تنها باعث افزایش کیفیت و دقت مدل‌ها می‌شود بلکه زمان توسعه و عرضه را نیز به‌طرز قابل‌توجهی کاهش می‌دهد. در \lr{MLOps} این خط لوله‌ها در مراحل مختلف از جمله آموزش مدل، ارزیابی، استقرار و نظارت بر عملکرد مدل‌ها و همچنین داده‌ها استفاده می‌شوند \cite{MLOpsProd2}. از ابزارهای مناسب برای این کار می‌توان به \lr{Jenkins}\cite{Jenkins} و \lr{GitLab CI}\cite{GitLab} اشاره کرد.


\subsection{نقش ها}
در تولید یک پلتفرم \lr{MLOps}، نقش‌های متعددی وجود دارد که همکاری آن‌ها برای طراحی، مدیریت، اتوماسیون و بهره‌برداری از سیستم‌های یادگیری ماشین در محیط تولید بسیار حیاتی است. در ابتدا سهام‌دار کسب‌وکار\footnote{\lr{Business Stakeholder}} وظیفه تعیین اهداف کسب‌وکار و استراتژی بازگشت سرمایه محصول یادگیری ماشین را بر عهده دارد. معمار، معماری سیستم را طراحی کرده و فناوری‌های مناسب را انتخاب می‌کند. دانشمند داده مسئله کسب‌وکار را به مسئله یادگیری ماشین ترجمه کرده و مدل‌ها را مهندسی می‌کند. مهندس داده خط لوله‌های داده و ویژگی را ایجاد و مدیریت می‌کند و داده‌ها را به‌درستی به سیستم‌های پایگاه داده و انبار ویژگی‌ها تزریق می‌کند. مهندس نرم‌افزار با استفاده از الگوهای طراحی، مسئله یادگیری ماشین را به یک محصول مهندسی‌شده تبدیل می‌کند. مهندس \lr{DevOps} خودکارسازی \lr{CI/CD}، هماهنگ‌سازی جریان کاری یادگیری ماشین و استقرار مدل در تولید را تضمین می‌کند. در نهایت، مهندس \lr{MLOps} نقش ترکیبی از مهارت‌های چندگانه را دارد و زیرساخت یادگیری ماشین را ایجاد و مدیریت کرده، خط لوله‌های جریان کاری را خودکار می‌کند و مدل‌ها و زیرساخت را در تولید نظارت می‌کند. این نقش‌ها که در شکل 
~\ref{fig: mlops roles}
نشان داده شده است، با همکاری و هماهنگی نزدیک می‌توانند \lr{MLOps} را به شکلی مؤثر و کارآمد پیاده‌سازی کنند، که نتیجه آن یک سیستم یادگیری ماشین پایدار و قابل اعتماد در محیط تولید خواهد بود. همکاری میان این نقش‌ها تضمین می‌کند که تمام جنبه‌های مربوط به توسعه، استقرار و نگهداری مدل‌های یادگیری ماشین به‌درستی مدیریت شود و به اهداف کسب‌وکار دست یابند.
\begin{figure}[t]
	\centering
	\includegraphics[scale=0.5]{mlops-roles.png}
	\caption{نقش‌ها و اشتراکات آن‌ها در پارادایم \lr{MLOps}}
	\label{fig: mlops roles}
\end{figure}

\section{معماری جامع}
 \begin{figure}[!b]
 	\centering
 	\includegraphics[scale=0.9]{mlops-architecture.jpg}
 	\caption{معماری جامع \lr{MLOps} \cite{basearticle}}
 	\label{fig: mlops architecture}
 \end{figure}
 
 بر اساس اصول، اجزا و نقش‌های بیان‌شده، یک معماری جامع از یک پلتفرم \lr{MLOps} طراحی شده است. این معماری که در شکل 
 ~\ref{fig: mlops architecture}
 نشان داده شده، جریان‌کارها و ترتیب وظایف در مراحل مختلف را ترسیم می‌کند. این معماری به‌گونه‌ای طراحی شده که کاربران می‌توانند مناسب‌ترین فناوری‌ها و چارچوب‌ها را بر اساس نیازهای خود انتخاب کنند. این انعطاف‌پذیری به کاربران این امکان را می‌دهد که پلتفرم \lr{MLOps} را با استفاده از ترکیبی از ابزارهای متن‌باز، استفاده از سرویس‌های ابری یا رویکردهای ترکیبی پیاده‌سازی کنند. نرم‌افزارهای سازمانی و خدمات ابری اغلب از طریق \lr{API}‌ها با ابزارهای متن‌باز یکپارچه می‌شوند و امکان ترکیب بی‌دردسر فناوری‌های مختلف را فراهم می‌کنند. این معماری یک معماری جامع بوده و هر سازمان می‌تواند برحسب نیاز و هدف خود در حل مسئله یادگیری ماشین، این معماری را شخصی‌سازی کرده و از پیاده‌سازی قسمت‌هایی از آن صرف‌نظر کند \cite{basearticle}.
 

\subsubsection{مرحله اولیه}
در فرآیند شروع محصول \lr{MLOps}، اولین مرحله با تحلیل کسب‌وکار آغاز می‌شود. کارشناس مربوط وظیفه دارد تا مشکلاتی را شناسایی کند که با استفاده از یادگیری ماشین قابل حل باشند. پس از شناسایی مشکل، معمار وارد عمل می‌شود. او طراحی معماری کلی سیستم یادگیری ماشین را تعریف کرده و پس از ارزیابی دقیق، تکنولوژی‌های مورد نیاز را انتخاب می‌کند. در مرحله بعدی، دانشمند داده وارد فرآیند می‌شود. دانشمند داده باید از هدف کسب‌وکار، یک مسئله یادگیری ماشین استخراج کند. این مسئله بسته به ماهیت مشکل کسب‌وکار می‌تواند شامل طبقه‌بندی، رگرسیون یا دیگر روش‌های یادگیری ماشین باشد. برای این منظور، دانشمند داده با همکاری مهندس داده باید داده‌های موجود را تجزیه و تحلیل کند تا بهترین رویکرد برای حل مسئله را انتخاب کند. این مرحله نیازمند دانش عمیق از روش‌های مختلف یادگیری ماشین و توانایی تطبیق آن‌ها با نیازهای خاص پروژه است. نکته مهم در این فرآیند، نیاز به داده‌های برچسب‌گذاری‌شده است که برای الگوریتم‌های نظارت‌شده ضروری هستند. در این معماری منابع داده از قبل دارای داده‌های برچسب‌گذاری‌شده بوده‌اند، زیرا فرآیند برچسب‌گذاری در مراحل قبلی انجام شده است.


\subsubsection{خط لوله مهندسی ویژگی}
در فرآیند توسعه مدل‌های یادگیری ماشین، مهندسی ویژگی‌ها\footnote{\lr{Feature Engineering}} به‌عنوان یکی از گام‌های حیاتی شناخته می‌شود که مستلزم تعیین نیازمندی‌های اساسی و پیاده‌سازی خط لوله مهندسی ویژگی‌ها است. این مرحله شامل تعریف و پیاده‌سازی قواعد تبدیل و پاک‌سازی داده‌ها، و همچنین ایجاد ویژگی‌های جدید و پیشرفته بر اساس ویژگی‌های موجود است. ابتدا نیازمندی‌های مهندسی ویژگی‌ها توسط متخصص داده و مهندس داده تعریف می‌شوند. در این مرحله، قواعد تبدیل داده‌ها\footnote{\lr{Data Transformation}} مانند نرمال‌سازی و تجمیع، و همچنین قواعد پاک‌سازی داده‌ها\footnote{\lr{Data Cleaning}} تعیین می‌شوند تا داده‌ها به فرمت قابل استفاده تبدیل شوند. این قواعد اولیه، به‌صورت تکراری و بر اساس بازخوردهای حاصل از مراحل آزمایشی مهندسی مدل و یا از طریق نظارت بر عملکرد مدل، تنظیم و بهبود می‌یابند.

با تعریف نیازمندی‌های اولیه، مهندس داده و مهندس نرم‌افزار اقدام به ساخت نمونه اولیه خط لوله تولید ویژگی‌ها می‌کنند. این خط لوله باید به‌صورت مداوم و بر اساس بازخوردهای دریافتی از مراحل مختلف، به‌روزرسانی و بهبود یابد. مراحل کلیدی پیاده‌سازی خط لوله تولید ویژگی‌ها به‌صورت زیر است:
\begin{itemize}
	\item 
	اتصال به داده‌های خام:
	اولین مرحله در پیاده‌سازی خط لوله تولید ویژگی‌ها، اتصال به منابع داده خام است. این داده‌ها می‌توانند از منابع مختلفی مانند داده‌های جریانی\footnote{\lr{Streaming Data}}، داده‌های دسته‌ای\footnote{\lr{batch data}} یا داده‌های ذخیره‌شده در ابر\footnote{\lr{Cloud Storage}} باشند. داده‌های جریانی به‌صورت پیوسته و بلادرنگ دریافت می‌شوند، داده‌های دسته‌ای ثابت به‌صورت دوره‌ای و در حجم بالا جمع‌آوری و پردازش می‌شوند و داده‌های ذخیره‌شده در ابر از طریق سیستم‌های ابری مقیاس‌پذیر و انعطاف‌پذیر ذخیره می‌شوند. اتصال به منابع داده باید به‌گونه‌ای انجام شود که داده‌ها به‌راحتی قابل استخراج و پردازش باشند.
	\item 
	استخراج داده‌ها:
	پس از اتصال به منابع داده، مرحله بعدی استخراج داده‌ها از این منابع است. این مرحله شامل خواندن داده‌ها از پایگاه‌های داده، فایل‌های \lr{CSV} یا دیگر منابع داده است.
	\item 
	پیش‌پردازش داده‌ها:
	در این مرحله، داده‌های استخراج‌شده برای تبدیل به فرم قابل استفاده، پیش‌پردازش می‌شوند. پیش‌پردازش شامل مراحل مختلفی مانند پاک‌سازی داده‌ها، مدیریت مقادیر مفقود، حذف نویز، و نرمال‌سازی مقادیر است. هدف اصلی این مرحله، آماده‌سازی داده‌ها به‌گونه‌ای است که بتوانند به‌عنوان ورودی‌های مدل یادگیری ماشین استفاده شوند.
	\item 
	استخراج ویژگی‌های جدید و پیشرفته:
	یکی از مهم‌ترین مراحل در خط لوله تولید ویژگی‌ها، استخراج ویژگی‌های جدید و پیشرفته است. این ویژگی‌ها بر اساس ویژگی‌های موجود و با استفاده از تکنیک‌های مختلفی مانند ترکیب ویژگی‌ها، اعمال توابع ریاضی، و بهره‌گیری از روش‌های آماری ایجاد می‌شوند. این مرحله به مدل یادگیری ماشین کمک می‌کند تا الگوهای پیچیده‌تری را در داده‌ها شناسایی کند و دقت پیش‌بینی‌های خود را افزایش دهد.
	\item 
	انتقال ویژگی‌ها به انبار ویژگی‌ها:
	در نهایت، داده‌های پردازش‌شده و ویژگی‌های محاسبه‌شده به انبار ویژگی‌ها وارد می‌شوند. این انبار می‌تواند شامل پایگاه‌های داده آنلاین یا آفلاین باشد. این بارگذاری باید به‌گونه‌ای انجام شود که دسترسی سریع و کارآمد به داده‌ها برای مراحل بعدی آموزش مدل فراهم شود.
\end{itemize}

در خط تولید ویژگی‌ها، مهندس نرم‌افزار به کمک مهندس داده کدهای مورد نیاز برای \lr{CI/CD} و هماهنگ‌سازی را تعریف می‌کند تا وظایف خط تولید ویژگی‌ها به‌درستی هماهنگ شوند. این نقش شامل تنظیم منابع زیرساختی برای اطمینان از مقیاس‌پذیری و عملکرد بهینه خط تولید است. با این تنظیمات، خط تولید ویژگی‌ها می‌تواند به‌طور مداوم به‌روزرسانی شده و بر اساس بازخوردها بهبود یابد، که این امر بهبود عملکرد مدل‌های یادگیری ماشین را تضمین می‌کند.

برای پیاده‌سازی خطوط تولید ویژگی‌ها، از ابزارها و فناوری‌های مختلفی از جمله ابزارهای \lr{ETL} سنتی مانند \lr{Apache Airflow} استفاده می‌شوند. همچنین از \lr{Feast} به همراه پایگاه داده‌های معروف مانند \lr{PostgreSQL} و \lr{Redis} نیز برای انبار ویژگی‌ها استفاده می‌شود.

\subsubsection{بررسی و آزمایش}
مرحله آزمایش مدل در فرآیند یادگیری ماشین یک بخش حیاتی است که بیشتر توسط دانشمند داده به همراه مهندس نرم‌افزار انجام می‌شود. قبل از شروع به کار، مهندس داده به همراه مهندس نرم‌افزار برای اطمینان از عملکرد درست ابزار و منابع، محیط و سخت‌افزار را پیکربندی می‌کنند. حال فرآیند آزمایش مدل شروع می‌شود:
\begin{itemize}
	\item 
	اتصال به انبار ویژگی:
	دانشمند داده به سیستم انبار ویژگی‌ها متصل می‌شود تا داده‌ها را برای تجزیه و تحلیل دریافت کند. در صورت نیاز، داده خام نیز می‌تواند برای تحلیل‌های اولیه مورد استفاده قرار گیرد. اگر تغییراتی در داده‌ها لازم باشد، این تغییرات به تیم مهندسی داده گزارش می‌شود، که نتیجه آن می‌تواند منجر به تغییر قواعد تبدیل، پاک‌سازی داده‌ها و خط تولید ویژگی‌ها شود.
	\item 
	آماده‌سازی و اعتبارسنجی داده‌ها:
	داده‌ها از سیستم انبار ویژگی‌ها جمع‌آوری و اعتبارسنجی می‌شوند. این مرحله شامل آماده‌سازی داده‌ها و تقسیم آن‌ها به مجموعه‌های آموزش و تست و ارزیابی است تا مدل‌ها بتوانند به‌طور مؤثری آموزش داده شوند.
	\item 
	آموزش و اعتبارسنجی مدل:
	در این مرحله، دانشمند داده الگوریتم‌های مختلف و پارامترهای آن‌ها را ارزیابی می‌کند تا بهترین ترکیب را پیدا کند. آموزش مدل با استفاده از داده‌های آموزشی شروع می‌شود و مهندس نرم‌افزار در ایجاد کدهای آموزشی بهینه کمک می‌کند. مدل‌ها با استفاده از پارامترهای مختلف به‌صورت تعاملی آموزش و اعتبارسنجی می‌شوند. این فرآیند تکراری است و تا زمانی که مدل به عملکرد مطلوبی برسد، ادامه می‌یابد. هدف این مرحله شناسایی بهترین الگوریتم و پارامترهای بهینه است.
	\item 
	استخراج مدل و ثبت کد:
	پس از شناسایی و انتخاب بهترین مدل، دانشمند داده مدل نهایی را استخراج کرده و کدهای مربوطه را در مخزن کد منبع قرار می‌دهد. این کدها شامل تمامی اسکریپت‌ها و مستنداتی است که برای تولید، آموزش و ارزیابی مدل استفاده شده‌اند. در همین زمان، مهندس \lr{DevOps} یا مهندس یادگیری ماشین کدهای مربوط به خط لوله یادگیری ماشین را آماده و در مخزن قرار می‌دهد. این خط لوله شامل اسکریپت‌ها و تنظیماتی است که برای خودکارسازی فرآیندهای مختلف یادگیری ماشین مانند آموزش، ارزیابی و استقرار مدل مورد نیاز است. با انجام این کار، سیستم \lr{CI/CD} به‌صورت خودکار تغییرات را تشخیص داده و فرآیند ساخت، آزمون و تحویل مدل را آغاز می‌کند. در مرحله ساخت، مولفه‌های مدل\footnote{\lr{Model Artifacts}} و کدهای مرتبط ایجاد می‌شوند. در مرحله آزمون، صحت و عملکرد مدل بررسی می‌شود و در نهایت، در مرحله تحویل مدل نهایی به مخزن مولفه‌ها ارسال می‌شود تا برای استفاده در محیط عملیاتی آماده باشد.
\end{itemize}

در مرحله آزمایش، ابزارهای مبتنی بر \lr{Notebook} مانند \lr{Jupyter} \cite{Jupyter} به‌طور گسترده استفاده می‌شوند. این ابزارها به دانشمندان داده اجازه می‌دهند تا داده‌ها را آماده، مدل‌ها را آموزش، ارزیابی و بهینه‌سازی کنند. همچنین برای پیگیری و مدیریت آزمایش‌ها از ابزارهایی مانند \lr{MLflow} و \lr{TensorBoard} استفاده می‌شود.

\subsubsection{خودکارسازی جریان‌ کاری یادگیری ماشین}
خودکارسازی جریان کاری یادگیری ماشین شامل مجموعه‌ای از فرآیندهای پیچیده و حیاتی است که توسط مهندس \lr{DevOps} و مهندس یادگیری ماشین مدیریت می‌شود. این فرآیندها شامل مدیریت محیط‌های اجرایی و زیرساخت‌های لازم برای آموزش مدل‌ها است که از منابع سخت‌افزاری و فریم‌ورک‌های محاسباتی نظیر کوبرنتیز استفاده می‌کنند. در این سیستم، یک مؤلفه ارکستراسیون وظایف مختلف را در جریان کاری خودکار یادگیری ماشین هماهنگ می‌کند. این مؤلفه وظایف را به محیط‌های مجزا (مانند کانتینرها) تخصیص داده و فراداده‌های هر وظیفه را در قالب لاگ‌ها و سایر اطلاعات جمع‌آوری می‌کند. مراحل اجرای این فرآیند که به قسمت قبل خیلی شباهت دارد به‌صورت زیر است:
\begin{itemize}
	\item
	استخراج داده‌ها:
	اولین مرحله در این فرآیند، استخراج داده‌ها از سیستم‌های انبار ویژگی‌ها است. این داده‌ها می‌توانند از پایگاه‌های داده آنلاین یا آفلاین استخراج شوند. بسته به نیاز مورد استفاده، داده‌ها از منابع مختلفی استخراج شده و برای مراحل بعدی آماده می‌شوند.
	\item
	آماده‌سازی و اعتبارسنجی داده‌ها:
	در این مرحله، داده‌ها به‌صورت خودکار آماده‌سازی و اعتبارسنجی می‌شوند. همچنین، تقسیم‌بندی داده‌ها به مجموعه‌های آموزش و تست نیز به‌صورت خودکار انجام می‌گیرد. این فرآیند تضمین می‌کند که داده‌های ورودی به مدل‌ها با کیفیت و قابل‌اعتماد باشند.
	\item
	آموزش مدل نهایی:
	پس از آماده‌سازی داده‌ها، مدل نهایی بر روی داده‌های جدید و نادیده آموزش داده می‌شود. الگوریتم‌ها و ابرپارامترها بر اساس تنظیمات مراحل آزمایشی قبلی از پیش تعریف شده‌اند. در این مرحله، مدل آموزش داده شده و بهینه‌سازی می‌شود تا بهترین عملکرد ممکن را ارائه دهد.
	\item
	ارزیابی و تنظیم مدل:
	مدل آموزش‌دیده شده به‌صورت خودکار ارزیابی می‌شود و در صورت نیاز، ابرپارامترها تغییر می‌کنند. این فرآیند به‌صورت تکراری انجام می‌شود تا زمانی که معیارهای عملکرد نشان‌دهنده نتایج مطلوب باشند. این تکرارها تا دستیابی به یک مدل با عملکرد بهینه ادامه می‌یابند.
	\item
	ثبت و ذخیره مدل:
	مدل نهایی آموزش‌دیده شده سپس ذخیره شده و به یک مخزن مدل منتقل می‌شود. این مخزن مدل، مدل‌ها را به‌صورت کد یا کانتینر همراه با فایل‌های تنظیمات و محیط ذخیره می‌کند. این امر تضمین می‌کند که مدل‌ها به‌راحتی قابل دسترسی و استفاده مجدد باشند.
\end{itemize}

برای هر بار آموزش مدل، مخزن فراداده‌ها پارامترهای مورد نیاز برای آموزش مدل و معیارهای عملکرد حاصل را ثبت می‌کند. این شامل ثبت جزئیات هر دوره آموزش مدل، مانند تاریخ و زمان آموزش، مدت‌زمان، پارامترهای استفاده‌شده و معیارهای عملکرد مدل می‌باشد. همچنین نسخه و وضعیت مدل (مثلاً آماده برای تولید یا در حال توسعه) نیز ثبت می‌شود.

پس از انتقال مدل با عملکرد بالا از مرحله آزمایش به تولید، این مدل به‌طور خودکار به مهندس \lr{DevOps} یا مهندس یادگیری ماشین برای استقرار مدل تحویل داده می‌شود. در این مرحله، ابزار مدیریت \lr{CI/CD} مانند \lr{ArgoCD}، خط لوله \lr{CD} را اجرا می‌کند. مدل آماده و کدهای استقرار مدل که توسط مهندس نرم‌افزار تهیه شده‌اند، فراخوانی می‌شوند. خط لوله \lr{CD} وظیفه ساخت و آزمایش مدل و کدهای استقرار مدل برای استقرار در محیط عملیاتی را بر عهده دارد. برنامه‌های استقرار مدل اغلب با استفاده از یک کانتینر پیاده‌سازی و تنظیم می‌شوند و درخواست‌های پیش‌بینی را از طریق \lr{REST API} پاسخ می‌دهند. هنگام استقرار یک برنامه یادگیری ماشین، استفاده از آزمایش \lr{A/B} به‌عنوان یک استراتژی تست خوب توصیه می‌شود تا در یک سناریوی واقعی مشخص شود که کدام مدل بهتر عمل می‌کند.

مؤلفه نظارتی به‌صورت پیوسته عملکرد مدل و زیرساخت‌ها را پایش می‌کند. زمانی که یک آستانه خاص مانند تغییر در توزیع خروجی مدل تشخیص داده شود، اطلاعات از طریق حلقه بازخورد ارسال می‌شود. این حلقه امکان آموزش و بازآموزی مداوم\footnote{\lr{Continuous Training (CT)}} و بهبود مستمر را فراهم می‌کند. اطلاعات از مؤلفه نظارتی مدل به چندین نقطه مانند مرحله آزمایش، مرحله تولید ویژگی و مهندسی داده منتقل می‌شود. بازخورد به مرحله آزمایش توسط دانشمند داده برای بهبود بیشتر مدل‌ها مورد استفاده قرار می‌گیرد. بازخورد به مرحله تولید ویژگی نیز امکان تغییر در تولید ویژگی‌ها برای سیستم انبار ویژگی‌ها را فراهم می‌کند. تشخیص رانش داده به‌عنوان یک مکانیزم بازخورد نیز می‌تواند آموزش مستمر را فعال کند. رانش داده به تغییرات تدریجی یا ناگهانی در توزیع داده‌های ورودی مدل‌های یادگیری ماشین گفته می‌شود که می‌تواند باعث کاهش دقت و کارایی مدل‌ها شود. این تغییرات ممکن است به دلیل عوامل مختلفی مانند تغییر در رفتار کاربران، تغییر در شرایط محیطی، خرابی سنسورها و یا تغییرات سیستمی رخ دهند. رانش داده به دو نوع اصلی تقسیم می‌شود:

\textbf{رانش مفهوم}\footnote{\lr{Concept Drift}}:
تغییر در توزیع برچسب‌ها یا خروجی‌ها که نشان‌دهنده تغییر در الگوهای زیرین داده‌هاست.

\textbf{رانش ویژگی}\footnote{\lr{Feature Drift}}:
تغییر در توزیع ویژگی‌ها یا ورودی‌های مدل که می‌تواند به دلیل تغییر در محیط یا منابع داده‌ها باشد.

تشخیص رانش داده اهمیت زیادی دارد زیرا به مدل‌ها کمک می‌کند تا با تغییرات جدید سازگار شوند و از کاهش کارایی جلوگیری کنند. این تشخیص می‌تواند از طریق مقایسه توزیع‌های آماری قدیم و جدید داده‌ها و استفاده از الگوریتم‌های مختلف انجام شود. هنگامی که رانش داده تشخیص داده شود، مدل‌ها می‌توانند مجدداً آموزش داده شوند تا با شرایط جدید سازگار شوند و کارایی مطلوب خود را حفظ کنند.

تکنولوژی‌ها و ابزار برای پیاده‌سازی خط لوله خودکار یادگیری ماشین شامل \lr{Apache Airflow}، \lr{Kubeflow Pipelines} و \lr{AWS SageMaker} هستند. یک مثال از کاربرد صنعتی یک خط لوله خودکار یادگیری ماشین با استفاده از \lr{Airflow} در زمینه تبلیغات آنلاین است \cite{MLOpsArch3}. این شرکت از \lr{Airflow} برای خودکارسازی فرآیند آموزش و استقرار مدل‌های یادگیری ماشین برای هدف‌گذاری و بهینه‌سازی تبلیغات استفاده می‌کند. در این خط لوله، داده‌های بزرگی از منابع مختلف مانند داده‌های کلیک‌استریم وب‌سایت، جمعیت‌شناسی کاربران و داده‌های عملکرد کمپین استخراج، تبدیل و بارگذاری می‌شوند. این داده‌ها سپس از یک سری مراحل پیش‌پردازش و مهندسی ویژگی عبور می‌کنند که به‌عنوان اپراتورهای \lr{Airflow} پیاده‌سازی شده‌اند. در مرحله بعد، مدل‌های مختلف یادگیری ماشین بر روی داده‌های پردازش‌شده آموزش داده و ارزیابی می‌شوند. در نهایت، مدل با بهترین عملکرد برای تصمیم‌گیری‌های هدف‌گذاری تبلیغات بی‌درنگ به محیط تولید منتقل می‌شود. در این مثال، برای خودکارسازی کل فرآیند از جمله زمان‌بندی، نظارت و اجرای مجدد وظایف شکست‌خورده از \lr{Airflow} استفاده می‌شود.



